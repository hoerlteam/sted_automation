{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "source": [
    "# Utilities for sorting and classifiying STED images of spot spairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and defs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, imread, median_filter, gaussian_laplace, sobel\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.spatial import kdtree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 6]\n",
    "\n",
    "def mkdir_if_necessary(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "        \n",
    "        \n",
    "def exists_with_postfix(path, postfix=\".jpg\"):\n",
    "    return os.path.exists(path + postfix)\n",
    "\n",
    "def sort_overviews(d):\n",
    "    files = next(os.walk(d))[2]\n",
    "\n",
    "    ov_d = os.path.join(d, 'overviews')\n",
    "    mkdir_if_necessary(ov_d)\n",
    "\n",
    "    p = re.compile('.*?field.*?sted.*?')\n",
    "\n",
    "    for f in files:\n",
    "        if not re.match(p, f):\n",
    "            shutil.move(os.path.join(d, f), os.path.join(ov_d, f))\n",
    "            \n",
    "def recommend_quality(im, thresh_brightest = 10, max_dist=25):\n",
    "    i1 = im[:,:,0]\n",
    "    g1 = gaussian_filter(i1, 1)\n",
    "    i2 = im[:,:,1]\n",
    "    g2 = gaussian_filter(i2, 1)\n",
    "    p1 = peak_local_max(g1, min_distance=2)\n",
    "    p2 = peak_local_max(g2, min_distance=2)\n",
    "    \n",
    "    p1i = sorted([(i1[p1[i,0], p1[i,1]], i) for i in range(len(p1))], key=lambda x: x[0], reverse=True)\n",
    "    p2i = sorted([(i2[p2[i,0], p2[i,1]], i) for i in range(len(p2))], key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    if p1i[0][0] < thresh_brightest / 2 * np.mean(i1):\n",
    "        print('BAD: channel 1 dark')\n",
    "        return 'b'\n",
    "    \n",
    "    if p2i[0][0] < thresh_brightest / 2 * np.mean(i2):\n",
    "        print('BAD: channel 2 dark')\n",
    "        return 'b'\n",
    "    \n",
    "    if p1i[0][0] < thresh_brightest * np.mean(i1):\n",
    "        print('MEDIOCRE: channel 1 dark')\n",
    "        return 'm'\n",
    "    \n",
    "    if p2i[0][0] < thresh_brightest * np.mean(i2):\n",
    "        print('MEDIOCRE: channel 2 dark')\n",
    "        return 'm'\n",
    "        \n",
    "    \n",
    "    halflife1 = sum([p1i[i][0] > 0.67 * p1i[0][0] for i in range(len(p1i))]) \n",
    "    halflife2 = sum([p2i[i][0] > 0.67 * p2i[0][0] for i in range(len(p2i))]) \n",
    "    \n",
    "    print('Found ' + str(halflife1) + ' candidate peaks in channel 1')\n",
    "    print('Found ' + str(halflife2) + ' candidate peaks in channel 2')\n",
    "    \n",
    "    if (halflife1 > 5):\n",
    "        print('BAD: found too many peaks in channel 1')\n",
    "        return 'b'\n",
    "    \n",
    "    if (halflife2 > 5):\n",
    "        print('BAD: found too many peaks in channel 2')\n",
    "        return 'b'\n",
    "    \n",
    "    p1good = [p1[p1i[i][1]] for i in range(halflife1)]\n",
    "    p2good = [p2[p2i[i][1]] for i in range(halflife2)]\n",
    "    tree = kdtree.KDTree(p1good)\n",
    "    \n",
    "    mindist = np.min(tree.query(p2good)[0])\n",
    "    print('approximate minimal distance: ' + str(mindist))\n",
    "    \n",
    "    if (mindist > max_dist):\n",
    "        print('MEDIOCRE: minimal distance too high')\n",
    "        return 'm'\n",
    "    \n",
    "    print('GOOD')\n",
    "    return 'g'\n",
    "\n",
    "def getfeatures(img):\n",
    "    \n",
    "    i1 = im[:,:,0]\n",
    "    g1 = gaussian_filter(i1, 1)\n",
    "    i2 = im[:,:,1]\n",
    "    g2 = gaussian_filter(i2, 1)\n",
    "    p1 = peak_local_max(g1, min_distance=2)\n",
    "    p2 = peak_local_max(g2, min_distance=2)\n",
    "    \n",
    "    p1i = sorted([(i1[p1[i,0], p1[i,1]], i) for i in range(len(p1))], key=lambda x: x[0], reverse=True)\n",
    "    p2i = sorted([(i2[p2[i,0], p2[i,1]], i) for i in range(len(p2))], key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    halflife1 = sum([p1i[i][0] > 0.67 * p1i[0][0] for i in range(len(p1i))]) \n",
    "    halflife2 = sum([p2i[i][0] > 0.67 * p2i[0][0] for i in range(len(p2i))])\n",
    "    \n",
    "    #print(halflife1)\n",
    "    #print(halflife2)\n",
    "    \n",
    "    p1good = [p1[p1i[i][1]] for i in range(halflife1)]\n",
    "    p2good = [p2[p2i[i][1]] for i in range(halflife2)]\n",
    "    tree = kdtree.KDTree(p1good)\n",
    "    \n",
    "    q = tree.query(p2good)\n",
    "    \n",
    "    m2 = np.argmin(q[0])\n",
    "    m1 = q[1][m2]\n",
    "    d = q[0][m2]\n",
    "    \n",
    "    features = [np.mean(i1), np.mean(i2), np.var(i1), np.var(i2), halflife1, halflife2, d]\n",
    "    \n",
    "    for sigma in [0.7, 1 , 1.5 , 2.25 , 3.5, 5]:\n",
    "        features.append(gaussian_filter(i1,sigma)[tuple(p1good[m1])])\n",
    "        features.append(gaussian_filter(i2,sigma)[tuple(p2good[m2])])\n",
    "        features.append(gaussian_laplace(i1,sigma)[tuple(p1good[m1])])\n",
    "        features.append(gaussian_laplace(i2,sigma)[tuple(p2good[m2])])\n",
    "    \n",
    "    features.append(sobel(i1)[tuple(p1good[m1])])\n",
    "    features.append(sobel(i2)[tuple(p2good[m2])])\n",
    "    features.append(i1[tuple(p1good[m1])])\n",
    "    features.append(i2[tuple(p2good[m2])])\n",
    "    \n",
    "    return [float(f) for f in features]\n",
    "\n",
    "def predict_ml(img, sc, cls):\n",
    "    feat = np.array(getfeatures(img)).reshape(1,-1)\n",
    "    return ['good', 'bad', 'mediocre'][cls.predict(sc.transform(feat))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Classifier Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init features\n",
    "features = []\n",
    "classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate features and classes from\n",
    "# list of dictionaries to use as training data\n",
    "\n",
    "# dicts with 30 percent STED images\n",
    "ds = [\n",
    "    '/Users/david/Desktop/8th_shipment_20170130/mixed_HS1_HS4_B/K562_B/',\n",
    "    '/Users/david/Desktop/8th_shipment_20170130/mixed_HS1_HS4_B/GM_B/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS1_HS4_A/GM_A/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS1_HS4_A/K562_A/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS1_HS4_B/GM_B/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS1_HS4_B/K562_B/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS2_HBG2_A/GM_A/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS2_HBG2_A/K562_A/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS2_HBG2_B/GM_B/',\n",
    "    '/Users/david/Desktop/9th_shipment_20170216/mixed_HS2_HBG2_B/K562_B/',\n",
    "    '/Users/david/Desktop/VisitFebMar2017/visit_feb_20170221/HS1_HS4_A/K562_Apos1/',\n",
    "    '/Users/david/Desktop/VisitFebMar2017/visit_feb_20170221/HS1_HS4_A/K562_Apos2/',\n",
    "    '/Users/david/Desktop/VisitFebMar2017/visit_feb_20170222/HS1_HS4_B/K562_Bpos1/',\n",
    "    '/Users/david/Desktop/VisitFebMar2017/visit_feb_20170222/HS1_HS4_B/K562_Bpos2/'\n",
    "    ]\n",
    "\n",
    "for d in ds:\n",
    "    for di, _ , fl in os.walk(d):\n",
    "        for f in fl:\n",
    "            if f.endswith('.jpg') and di.split(os.sep)[-1] in ['good', 'bad', 'mediocre']:\n",
    "                im = imread(os.path.join(di, f))\n",
    "                features.append(getfeatures(im))\n",
    "                classes.append(['good', 'bad', 'mediocre'].index(di.split(os.sep)[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean classifier accuracy (10-fold c.v.): 0.882122779508\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# generate scaler and Random Forest classifier\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(features)\n",
    "\n",
    "cls = RandomForestClassifier(n_estimators=100)\n",
    "\n",
    "print('Mean classifier accuracy (10-fold c.v.): ' + \n",
    "      str(np.mean(cross_val_score(cls, sc.transform(features), [0 if x == 0 else 1 for x in classes], cv=10))))\n",
    "cls.fit(sc.transform(features), [0 if x == 0 else 1 for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save classifier and scaler\n",
    "\n",
    "with open('/Users/david/Desktop/scaler_30sted_2.pks', 'wb') as fd:\n",
    "    pickle.dump(sc, fd)\n",
    "    \n",
    "with open('/Users/david/Desktop/goodbadclassifier_30sted_2.pks', 'wb') as fd:\n",
    "    pickle.dump(cls, fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading a preexisting classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('/Users/david/Desktop/scaler_30sted_2.pks', 'rb') as fd:\n",
    "    sc = pickle.load(fd)\n",
    "\n",
    "with open('/Users/david/Desktop/goodbadclassifier_30sted_2.pks', 'rb') as fd:\n",
    "    cls = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 1: set the directory to process\n",
    "#dir_to_process = os.path.join(os.getcwd(), 'AutomatedAcquisitions')\n",
    "dir_to_process = '/Users/david/Desktop/VisitFebMar2017/visit_feb_20170306/HS2_HBG2/K562/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['HS2_HBG2', 'HS2Delta_HBG2']\n"
     ]
    }
   ],
   "source": [
    "### 2: move all the overview files into a separate folder\n",
    "dirs = [d for d in next(os.walk(dir_to_process))[1] if not d.startswith('.')]\n",
    "print(dirs)\n",
    "\n",
    "for d in dirs:\n",
    "    sort_overviews(os.path.join(dir_to_process, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 3: set subfolder to process\n",
    "d = os.path.join(dir_to_process, 'K562_HS2Delta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Sorting, ML assisted if classifier present"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### 4: SORTING into good/bad/mediocre\n",
    "\n",
    "\n",
    "gd_d = os.path.join(d, 'good')\n",
    "bd_d = os.path.join(d, 'bad')\n",
    "md_d = os.path.join(d, 'mediocre')\n",
    "\n",
    "mkdir_if_necessary(gd_d)\n",
    "mkdir_if_necessary(bd_d)\n",
    "mkdir_if_necessary(md_d)\n",
    "\n",
    "files = [f for f in next(os.walk(d))[2] if f.endswith('.msr')]\n",
    "\n",
    "for fi in files:\n",
    "    f = os.path.join(d,fi)\n",
    "    im = imread(f + \".jpg\")\n",
    "    \n",
    "    rec = None\n",
    "    if sc != None and cls != None:\n",
    "        rec = predict_ml(im, sc, cls)\n",
    "    \n",
    "    plt.imshow(im)\n",
    "    plt.show()\n",
    "    \n",
    "    if rec != None:\n",
    "        print(rec.upper())\n",
    "    \n",
    "    print('-----')\n",
    "    sys.stdout.flush()\n",
    "    decision = input(\"ISGOOD? [(g)ood/(b)ad/(m)ediocre] :\") or rec\n",
    "    dec = decision.upper()[0]\n",
    "        \n",
    "    if dec == \"G\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(gd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(gd_d, fi + \".jpg\"))\n",
    "    elif dec == \"B\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(bd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(bd_d, fi + \".jpg\"))\n",
    "    elif dec == \"M\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(md_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(md_d, fi + \".jpg\"))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Automated sorting, needs classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/ipykernel/__main__.py:143: VisibleDeprecationWarning: converting an array with ndim > 0 to an index will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "### 4a: SORTING into good/bad/(mediocre) AUTOMATED\n",
    "d = '/Users/david/Desktop/VisitFebMar2017/visit_feb_20170311/K562/HS2_HBG2/'\n",
    "\n",
    "gd_d = os.path.join(d, 'good')\n",
    "bd_d = os.path.join(d, 'bad')\n",
    "md_d = os.path.join(d, 'mediocre')\n",
    "\n",
    "mkdir_if_necessary(gd_d)\n",
    "mkdir_if_necessary(bd_d)\n",
    "mkdir_if_necessary(md_d)\n",
    "\n",
    "files = [f for f in next(os.walk(d))[2] if f.endswith('.msr')]\n",
    "\n",
    "for fi in files:\n",
    "    f = os.path.join(d,fi)\n",
    "    im = imread(f + \".jpg\")\n",
    "    \n",
    "    rec = predict_ml(im, sc, cls)\n",
    "    dec = rec.upper()[0]\n",
    "    \n",
    "    if dec == \"G\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(gd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(gd_d, fi + \".jpg\"))\n",
    "    elif dec == \"B\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(bd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(bd_d, fi + \".jpg\"))\n",
    "    elif dec == \"M\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(md_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(md_d, fi + \".jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
