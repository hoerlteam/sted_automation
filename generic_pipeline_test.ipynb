{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "# Generic Pipeline tests\n",
    "\n",
    "## Imspector-independent stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from itertools import count\n",
    "from pprint import pprint\n",
    "import json\n",
    "from queue import PriorityQueue\n",
    "from collections import defaultdict\n",
    "from time import time, sleep, clock\n",
    "import signal\n",
    "import hashlib\n",
    "import os\n",
    "from itertools import zip_longest, chain, cycle\n",
    "from unittest.mock import MagicMock\n",
    "\n",
    "#from jsonpath_ng import jsonpath, parse\n",
    "\n",
    "from spot_util import pair_finder_inner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _relative_spiral_generator(steps, start=[0,0]):\n",
    "    \"\"\"\n",
    "    generator for regular spiral coordinates around a starting point\n",
    "    with given step sizes\n",
    "    \"\"\"\n",
    "    n = 0\n",
    "    yield start.copy()\n",
    "    while True:\n",
    "        bookmark = [- n * steps[0] + start[0], n * steps[1] + start[0]]\n",
    "        for _ in range(2*n):\n",
    "            yield bookmark.copy()\n",
    "            bookmark[0] += steps[0]\n",
    "        for _ in range(2*n):\n",
    "            yield bookmark.copy()\n",
    "            bookmark[1] -= steps[1]\n",
    "        for _ in range(2*n):\n",
    "            yield bookmark.copy()\n",
    "            bookmark[0] -= steps[0]\n",
    "        for _ in range(2*n):\n",
    "            yield bookmark.copy()\n",
    "            bookmark[1] += steps[1]\n",
    "        n += 1\n",
    "\n",
    "\n",
    "        \n",
    "class LegacySpotPairFinder():\n",
    "    \"\"\"\n",
    "    wrapper for the 'old' spot pair detector\n",
    "    get_locations will return a list of coordinate lists\n",
    "    of scan coordinates (stage coordinates are ignored)\n",
    "    \"\"\"\n",
    "    def __init__(self, dataSource, sigma, thresholds, medianThresholds=[3,3], medianRadius=5):\n",
    "        self.dataSource = dataSource\n",
    "        self.sigma = sigma\n",
    "        self.thresholds = thresholds\n",
    "        self.medianThresholds = medianThresholds\n",
    "        self.medianRadius = medianRadius\n",
    "        self.plotDetections = False\n",
    "        \n",
    "    def withPlotDetections(plotDetections):\n",
    "        self.plotDetections = plotDetections\n",
    "        return self\n",
    "    \n",
    "    def get_locations(self):\n",
    "        data = self.dataSource.get_data()\n",
    "        if (data.numConfigurations < 1) or (data.numImages(0) < 2):\n",
    "            raise ValueError('too few images for LegacySpotPairFinder. The RichData provided needs to have two images in the first configuration.')\n",
    "        stack1 = data.data[0][0][0,:,:,:]\n",
    "        stack2 = data.data[0][1][0,:,:,:]\n",
    "        \n",
    "        setts = data.measurementSettings[0]\n",
    "        \n",
    "        pairsRaw = pair_finder_inner(stack1, stack2, self.sigma, self.thresholds, True, False, self.medianThresholds, self.medianRadius)\n",
    "        \n",
    "        offsOld = np.array([filter_dict(\n",
    "            setts, 'ExpControl/scan/range/{}/off'.format(c), False) for c in ['x', 'y', 'z']], dtype=float)\n",
    "        \n",
    "        lensOld = np.array([filter_dict(\n",
    "            setts, 'ExpControl/scan/range/{}/len'.format(c), False) for c in ['x', 'y', 'z']], dtype=float)\n",
    "        \n",
    "        pszOld = np.array([filter_dict(\n",
    "            setts, 'ExpControl/scan/range/{}/psz'.format(c), False) for c in ['x', 'y', 'z']], dtype=float)\n",
    "        \n",
    "        # TODO: do plotting\n",
    "        if self.plotDetections:\n",
    "            pass\n",
    "        \n",
    "        res = []\n",
    "        for pair in pairs:\n",
    "            pairT = np.array(pair, dtype=float)\n",
    "            res.append(list(offsOld - (lensOld /.2) + pairT * pszOld))\n",
    "        return res\n",
    "            \n",
    "        \n",
    "class AcquisitionPriorityQueue(PriorityQueue):\n",
    "    \"\"\"\n",
    "    slightly modified PriorityQueue to be able to enqueue non-orderable data\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        PriorityQueue.__init__(self)\n",
    "        self.ctr = count()\n",
    "    def put(self, item, prio):\n",
    "        PriorityQueue.put(self, (prio, next(self.ctr), item))\n",
    "    def get(self, *args, **kwargs):\n",
    "        lvl, _, item = PriorityQueue.get(self, *args, **kwargs)\n",
    "        return (lvl, item)\n",
    "        \n",
    "class _pipeline_level:\n",
    "    \"\"\"\n",
    "    named level in an acquisition pipeline\n",
    "    should not be used outside of a PipelineLevels object\n",
    "    \"\"\"\n",
    "    def __init__(self, parent, name):\n",
    "        self.parent = parent\n",
    "        self.name = name\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if type(self) != type(other):\n",
    "            return False\n",
    "        return self.name == other.name\n",
    "    \n",
    "    def __le__(self, other):\n",
    "        return self.parent.reversedLevels.index(self) <= self.parent.reversedLevels.index(other)\n",
    "    \n",
    "    def __lt__(self, other):\n",
    "        return self.parent.reversedLevels.index(self) < self.parent.reversedLevels.index(other)\n",
    "    \n",
    "    def __str__(self):\n",
    "        return self.name\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return str.__hash__(self.name)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.name\n",
    "\n",
    "\n",
    "class DelayedKeyboardInterrupt():\n",
    "    \"\"\"\n",
    "    context manager to allow finishing of one acquisition loop\n",
    "    before quitting queue due to KeyboardInterrupt\n",
    "    \n",
    "    modified from https://stackoverflow.com/a/21919644\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pipeline):\n",
    "        self.pipeline = pipeline\n",
    "    \n",
    "    def __enter__(self):\n",
    "        self.old_handler = signal.getsignal(signal.SIGINT)\n",
    "        signal.signal(signal.SIGINT, self.handler)\n",
    "\n",
    "    def handler(self, sig, frame):\n",
    "        self.pipeline.interrupted = True\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        signal.signal(signal.SIGINT, self.old_handler)\n",
    "    \n",
    "class PipelineLevels:\n",
    "    \"\"\"\n",
    "    ordered collection of _pipeline_level\n",
    "    \"\"\"\n",
    "    levels = []\n",
    "    def __init__(self, *args):\n",
    "        for arg in args:\n",
    "            lvl = _pipeline_level(self, arg)\n",
    "            self.levels.append(lvl)\n",
    "            setattr(self, arg, lvl)\n",
    "    @property\n",
    "    def reversedLevels(self):\n",
    "        return list(reversed(self.levels))\n",
    "\n",
    "class TimedStoppingCriterion():\n",
    "    \"\"\"\n",
    "    stopping criterion to stop after a set amount of time\n",
    "    \"\"\"\n",
    "    def __init__(self, maxtime):\n",
    "        self.maxtime = maxtime\n",
    "    def check(self, pipeline):\n",
    "        return time() > ( pipeline.startingTime + self.maxtime )\n",
    "    def desc(self, pipeline):\n",
    "        return 'STOPPING PIPELINE {}: maximum time exceeded'.format(pipeline.name)\n",
    "        \n",
    "class InterruptedStoppingCriterion():\n",
    "    \"\"\"\n",
    "    stopping criterion to check wether SIGINT was received and stop then\n",
    "    will also reset the signal status in parent AcquisitionPipeline\n",
    "    \"\"\"\n",
    "    def check(self, pipeline):\n",
    "        return pipeline.interrupted\n",
    "    def resetInterrupt(self, pipeline):\n",
    "        pipeline.interrupted = False\n",
    "    def desc(self, pipeline):\n",
    "        return 'STOPPING PIPELINE {}: interrupted by user'.format(pipeline.name)\n",
    "\n",
    "class AcquisitionTaskGenerator():\n",
    "    def __init__(self, level, *updateGens):\n",
    "        \n",
    "        self.level = level\n",
    "        self.updateGens = updateGens\n",
    "        self.delay = 0\n",
    "    \n",
    "    def withDelay(self, delay):\n",
    "        \"\"\"\n",
    "        a delay that will be added to every generated task\n",
    "        (e.g. to wait for the stage to move)\n",
    "        \"\"\"\n",
    "        self.delay = delay\n",
    "        return self\n",
    "    \n",
    "    def __call__(self, pipeline):\n",
    "        # broadcast meausurement updates ((u1, u2), (u3) -> ((u1, u3), (u2, u3)))\n",
    "        \n",
    "        updates = [updateGenI() for updateGenI in self.updateGens]\n",
    "        \n",
    "        maxMeasurements = max((len(updateI) for updateI in updates))\n",
    "        cyclesMeas = [cycle(updateI) for updateI in updates]\n",
    "        \n",
    "        for _ in range(maxMeasurements):\n",
    "            \n",
    "            # broadcast configurations within measurements\n",
    "            configs = [next(meas) for meas in cyclesMeas]\n",
    "            maxConfigs = max((len(confI) for confI in configs))\n",
    "            cyclesConfig = [cycle(confI) for confI in configs]\n",
    "            \n",
    "            finalConfs = []\n",
    "            \n",
    "            for _ in range(maxConfigs):\n",
    "                \n",
    "                finalConfs.append([next(upd) for upd in cyclesConfig])\n",
    "            \n",
    "            #print(json.dumps(finalConfs, indent=2))\n",
    "            pipeline.queue.put(AcquisitionTask(self.level).withUpdates(finalConfs).withDelay(self.delay), self.level)\n",
    "                \n",
    "class AcquisitionTask():\n",
    "    \"\"\"\n",
    "    a dummy acquisition task, that will repeat itself every second\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, pipelineLevel):\n",
    "        self.pipelineLevel = pipelineLevel\n",
    "        self.measurementUpdates = []\n",
    "        self.settingsUpdates = []\n",
    "        self.delay = 0\n",
    "        \n",
    "    def withUpdates(self, updates):\n",
    "        for u in updates:\n",
    "            measUpdates = [m for m,s in u]\n",
    "            settingsUpdates = [s for m,s in u]\n",
    "            self.measurementUpdates.append(measUpdates)\n",
    "            self.settingsUpdates.append(settingsUpdates)\n",
    "        return self\n",
    "    \n",
    "    def withDelay(self, delay=0):\n",
    "        self.delay = delay\n",
    "        return self\n",
    "        \n",
    "    @property\n",
    "    def numAcquisitions(self):\n",
    "        return len(self.measurementUpdates)\n",
    "    \n",
    "    def getUpdates(self, n):\n",
    "        return self.measurementUpdates[n], self.settingsUpdates[n]\n",
    "    \n",
    "    def getAllUpdates(self):\n",
    "        return [self.getUpdates(n) for n in range(self.numAcquisitions)]\n",
    "    \n",
    "    # TODO: move, this should become part of an analysis callback\n",
    "    def __call__(self, pipeline, *args, **kwargs):\n",
    "        print('pipeline {}: do dummy acquisition on level {}'.format(pipeline.name, self.pipelineLevel))\n",
    "        #sleep(1)\n",
    "        pipeline.queue.put(AcquisitionTask(self.pipelineLevel).withDelay(self.delay), self.pipelineLevel)\n",
    "\n",
    "\n",
    "class RichData:\n",
    "    \"\"\"\n",
    "    wrapper for data and settings of a measurement\n",
    "    holds hardware ('global') settings and per measurement settings\n",
    "    for each parameter set and a list of associated data\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.globalSettings = []\n",
    "        self.measurementSettings = []\n",
    "        self.data = []\n",
    "    \n",
    "    # TODO: remove defaults?\n",
    "    def append(self, globalSettings=None, measurementSettings=None, data=None):\n",
    "        self.globalSettings.append(globalSettings)\n",
    "        self.measurementSettings.append(measurementSettings)\n",
    "        self.data.append(data)\n",
    "    \n",
    "    @property\n",
    "    def numConfigurations(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def numImages(self, n):\n",
    "        if n < self.numConfigurations:\n",
    "            return len(self.data[n])\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "\n",
    "class DefaultNameHandler():\n",
    "    \"\"\"\n",
    "    file name handler\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, path, levels, prefix=None, ending = '.msr'):\n",
    "        self.path = path\n",
    "        self.levels = levels\n",
    "        self.ending = ending\n",
    "        if prefix is None:\n",
    "            hash_object = hashlib.md5(bytes(str(time()), \"utf-8\"))\n",
    "            hex_dig = hash_object.hexdigest()\n",
    "            self.prefix = str(hex_dig)\n",
    "        else:\n",
    "            self.prefix = prefix\n",
    "            \n",
    "        if not os.path.exists(path):\n",
    "            os.makedirs(path)\n",
    "            \n",
    "    def _mkdir_if_necessary(self):\n",
    "        pass\n",
    "            \n",
    "    def get_filename(self, idxes):\n",
    "        insert = chain.from_iterable(zip([l.name for l in self.levels.levels[0:len(idxes)]], idxes))\n",
    "        insert = list(insert)\n",
    "        return ((self.prefix + '_{}_{}' * len(idxes)).format(*insert) + self.ending)\n",
    "    \n",
    "    def get_path(self, idxes):\n",
    "        return os.path.join(self.path, self.get_filename(idxes))      \n",
    "        \n",
    "            \n",
    "class MockImspectorConnection():\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.getCurrentData = MagicMock(return_value = RichData())\n",
    "        self.makeMeasurementFromTask = MagicMock(return_value = None)\n",
    "        self.makeConfigurationFromTask = MagicMock(return_value = None)\n",
    "        self.runCurrentMeasurement = MagicMock(return_value = None)\n",
    "        self.saveCurrentMeasurement = MagicMock(return_value = None)\n",
    "        self.closeCurrentMeasurement = MagicMock(return_value = None)\n",
    "            \n",
    "\n",
    "            \n",
    "class ImspectorConnection():\n",
    "    \n",
    "    def __init__(self, im):\n",
    "        self.im = im\n",
    "        \n",
    "    def getCurrentData(self):\n",
    "        globalParams = self.im.parameters('')\n",
    "        measParameters = self.im.active_measurement().parameters('')\n",
    "        data = []\n",
    "        for name in im.active_measurement().stack_names():\n",
    "            data.append(np.copy(self.im.active_measurement().stack(name).data()))\n",
    "        return globalParams, measParameters, data\n",
    "    \n",
    "    def makeMeasurementFromTask(self, task):\n",
    "        ms = self.im.create_measurement()\n",
    "        measUpdates, confUpdates = task\n",
    "        measUpdates = update_dicts(*measUpdates)\n",
    "        confUpdates = update_dicts(*confUpdates)\n",
    "        \n",
    "        # we do the update twice to also set grayed-out values\n",
    "        ms.set_parameters('', measUpdates)\n",
    "        ms.set_parameters('', measUpdates)\n",
    "        self.im.set_parameters('', confUpdates)\n",
    "        self.im.set_parameters('', confUpdates)\n",
    "        \n",
    "    def makeConfigurationFromTask(self, task):\n",
    "        ms = self.im.active_measurement()\n",
    "        ac = ms.active_configuration()\n",
    "        ac = ms.clone(ac)\n",
    "        ms.activate(ac)\n",
    "        \n",
    "        measUpdates, confUpdates = task\n",
    "        measUpdates = update_dicts(*measUpdates)\n",
    "        confUpdates = update_dicts(*confUpdates)\n",
    "        \n",
    "        # we do the update twice to also set grayed-out values\n",
    "        ms.set_parameters('', measUpdates)\n",
    "        ms.set_parameters('', measUpdates)\n",
    "        self.im.set_parameters('', confUpdates)\n",
    "        self.im.set_parameters('', confUpdates)\n",
    "        \n",
    "    def runCurrentMeasurement(self):\n",
    "        ms = self.im.active_measurement()\n",
    "        #ms.activate(ms.configuration(ms.number_of_configurations()-1))\n",
    "        self.im.run(ms)\n",
    "        \n",
    "    def saveCurrentMeasurement(self, path):\n",
    "        ms = self.im.active_measurement()\n",
    "        ms.save_as(path)\n",
    "        \n",
    "    def closeCurrentMeasurement(self):\n",
    "        ms = self.im.active_measurement()\n",
    "        self.im.close(ms)\n",
    "\n",
    "class NewestDataSelector():\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, pipeline, level):\n",
    "        self.pipeline = pipeline\n",
    "        self.lvl = level\n",
    "    \n",
    "    def get_data(self):\n",
    "        # create index of measurement (indices of all levels until lvl)\n",
    "        latestMeasurementIdx = tuple([self.pipeline.counters[l] for l in self.pipeline.pipelineLevels.levels[\n",
    "                            0:self.pipeline.pipelineLevels.levels.index(self.lvl)+1]])\n",
    "        return self.pipeline.data.get(latestMeasurementIdx, None)\n",
    "\n",
    "\n",
    "class NewestSettingsSelector():\n",
    "    def __init__(self, pipeline, level):\n",
    "        self.level = level\n",
    "        self.pipeline = pipeline\n",
    "        \n",
    "    def __call__(self):\n",
    "        pipeline = self.pipeline\n",
    "        latestMeasurementIdx = tuple([pipeline.counters[l] for l in pipeline.pipelineLevels.levels[\n",
    "                            0:pipeline.pipelineLevels.levels.index(self.level)+1]])\n",
    "        data = pipeline.data.get(latestMeasurementIdx, None)\n",
    "        return [list(zip(data.measurementSettings, data.globalSettings))]\n",
    "        \n",
    "    \n",
    "class AcquisitionPipeline():\n",
    "    \n",
    "    \"\"\"\n",
    "    the main class\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, name):\n",
    "        \"\"\"\n",
    "        construct with name\n",
    "        \"\"\"\n",
    "        self.name = name\n",
    "        \n",
    "        self.pipelineLevels = None\n",
    "    \n",
    "        # we habe an InterruptedStoppingCriterion by default\n",
    "        self.stoppingConditions = [InterruptedStoppingCriterion()]\n",
    "        self.queue = AcquisitionPriorityQueue()\n",
    "        self.startingTime = None\n",
    "        self.counters = defaultdict(int)\n",
    "        self.data = defaultdict(RichData)\n",
    "        self.callbacks = defaultdict(list)\n",
    "        \n",
    "        # hold the Imspector connection\n",
    "        self.im = MockImspectorConnection()\n",
    "        \n",
    "        self.logger = None\n",
    "        self.nameHandler = None\n",
    "    \n",
    "        # the DelayedKeyboardInterrupt will indicate a received SIGINT here\n",
    "        self.interrupted = False\n",
    "    \n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        run the pipeline\n",
    "        \"\"\"\n",
    "        \n",
    "        # we use this context manager to handle interrupts so we can finish\n",
    "        # to acquisition we are in before stopping\n",
    "        with DelayedKeyboardInterrupt(self):            \n",
    "\n",
    "            # record starting time, so we can check wether a StoppingCondition is met\n",
    "            self.startingTime = time()\n",
    "\n",
    "            lvl = None\n",
    "            \n",
    "            while not self.queue.empty():\n",
    "\n",
    "                # get next task and its level\n",
    "                oldlvl = lvl\n",
    "                lvl, acquisition_task = self.queue.get()\n",
    "                \n",
    "                if oldlvl is None:\n",
    "                    self.counters[lvl] = -1\n",
    "                \n",
    "                # reset or increment indices\n",
    "                if (oldlvl != lvl):\n",
    "                    for l in self.pipelineLevels.levels:\n",
    "                        if l < lvl:\n",
    "                            self.counters[l] = -1\n",
    "                \n",
    "                self.counters[lvl] += 1\n",
    "                                \n",
    "                # create index of measurement (indices of all levels until lvl)\n",
    "                currentMeasurementIdx = tuple([self.counters[l] for l in self.pipelineLevels.levels[\n",
    "                            0:self.pipelineLevels.levels.index(lvl)+1]])\n",
    "\n",
    "                # go through updates sequentially (we might have multiple configurations per measurement)\n",
    "                for updatesI in range(acquisition_task.numAcquisitions):\n",
    "                    \n",
    "                    # update imspector\n",
    "                    if updatesI == 0:\n",
    "                        self.im.makeMeasurementFromTask(acquisition_task.getUpdates(updatesI))\n",
    "                    else:\n",
    "                        self.im.makeConfigurationFromTask(acquisition_task.getUpdates(updatesI))\n",
    "                    \n",
    "                    # we might want to sleep\n",
    "                    sleep(acquisition_task.delay)\n",
    "                    \n",
    "                    # run in imspector\n",
    "                    self.im.runCurrentMeasurement()\n",
    "                                \n",
    "                    # add data copy (of most recent configuration) to internal storage\n",
    "                    self.data[currentMeasurementIdx].append(*self.im.getCurrentData())\n",
    "                \n",
    "                # save and close in imspector\n",
    "                path = None\n",
    "                if self.nameHandler != None:\n",
    "                    path = self.nameHandler.get_path(currentMeasurementIdx)\n",
    "                print(path)\n",
    "                \n",
    "                # TODO: closing without saving might trigger UI dialog in Imspector\n",
    "                if not (path is None):\n",
    "                    self.im.saveCurrentMeasurement(path)\n",
    "                self.im.closeCurrentMeasurement()\n",
    "\n",
    "                # do the callbacks (this should do analysis and re-fill the queue)\n",
    "                callbacks_ = self.callbacks.get(lvl, None)\n",
    "                if not (callbacks_ is None):\n",
    "                    for callback_ in callbacks_:                    \n",
    "                        callback_(self)\n",
    "\n",
    "                # go through stopping conditions\n",
    "                for sc in self.stoppingConditions:\n",
    "                    if sc.check(self) == True:\n",
    "                        # reset interrupt flag if necessary\n",
    "                        if isinstance(sc, InterruptedStoppingCriterion):\n",
    "                            sc.resetInterrupt(self)\n",
    "                        print(sc.desc(self))\n",
    "                        break\n",
    "                # we went through all the loop iterations (no break)\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "            \n",
    "            print('PIPELINE {} FINISHED'.format(self.name))\n",
    "\n",
    "\n",
    "              \n",
    "    def withPipelineLevels(self, lvls):\n",
    "        \"\"\"\n",
    "        set pipeline levels, can be chained\n",
    "        \"\"\"\n",
    "        self.pipelineLevels = lvls\n",
    "        return self\n",
    "    \n",
    "    def withNameHandler(self, nh):\n",
    "        self.nameHandler = nh\n",
    "        return self\n",
    "    \n",
    "    def withImspectorConnection(self, im):\n",
    "        self.im = im\n",
    "        return self\n",
    "    \n",
    "    def withCallbackAtLevel(self, callback, lvl):\n",
    "        \"\"\"\n",
    "        set the callback for a level, can be chained\n",
    "        \"\"\"\n",
    "        if not (lvl in self.pipelineLevels.levels):\n",
    "            raise ValueError('{} is not a registered pipeline level'.format(lvl))\n",
    "        self.callbacks[lvl].append(callback)\n",
    "        return self\n",
    "    \n",
    "    def _withStoppingConditions(self, conds):\n",
    "        \"\"\"\n",
    "        reset the StoppingConditions, can be chained\n",
    "        \"\"\"\n",
    "        self.stoppingConditions.clear()\n",
    "        for condI in conds:\n",
    "            self.stoppingConditions.append(condI)\n",
    "        return self\n",
    "    \n",
    "    def withAddedStoppingCondition(self, cond):\n",
    "        \"\"\"\n",
    "        add a StoppingCondition, can be chained\n",
    "        \"\"\"\n",
    "        self.stoppingConditions.append(cond)\n",
    "        return self\n",
    "    \n",
    "    def withInitialTask(self, task, lvl):\n",
    "        \"\"\"\n",
    "        initialize the queue with the given task at the given level, can be chained\n",
    "        \"\"\"\n",
    "        self.queue = AcquisitionPriorityQueue()\n",
    "        self.queue.put(task, lvl)\n",
    "        return self\n",
    "    \n",
    "class JSONFileConfigLoader():\n",
    "    \"\"\"\n",
    "    load settings from JSON dump\n",
    "    \"\"\"\n",
    "    def __init__(self, measurementConfigFileNames, settingsConfigFileNames=None, asMeasurements=True):\n",
    "        self.measConfigs = []\n",
    "        self.asMeasurements = asMeasurements\n",
    "        for mFile in measurementConfigFileNames:\n",
    "            with open(mFile, 'r') as fd:\n",
    "                d = json.load(fd)\n",
    "                # remove, otherwise Imspector complains that those parameters do not exist (yet?)\n",
    "                d = remove_filter_from_dict(d, '/Measurement/LoopMeasurement')\n",
    "                d = remove_filter_from_dict(d, '/Measurement/ResumeIdx')\n",
    "                # remove, otherwise we will always use a set propset\n",
    "                d = remove_filter_from_dict(d, '/Measurement/propset_id')\n",
    "                self.measConfigs.append(d)\n",
    "        \n",
    "        self.settingsConfigs = []\n",
    "        if settingsConfigFileNames is None:\n",
    "            for _ in range(len(self.measConfigs)):\n",
    "                self.settingsConfigs.append(dict())\n",
    "        else:\n",
    "            if len(settingsConfigFileNames) != len(self.measConfigs):\n",
    "                raise ValueError('length of settings and measurement configs dont match')\n",
    "            for sFile in settingsConfigFileNames:\n",
    "                with open(sFile, 'r') as fd:\n",
    "                    self.settingsConfigs.append(json.load(fd))\n",
    "    \n",
    "    def __call__(self):\n",
    "        res = []\n",
    "        if self.asMeasurements:\n",
    "            for i in range(len(self.measConfigs)):\n",
    "                res.append([(self.measConfigs[i], self.settingsConfigs[i])])\n",
    "        else:\n",
    "            resInner = []\n",
    "            for i in range(len(self.measConfigs)):\n",
    "                resInner.append([(self.measConfigs[i], self.settingsConfigs[i])])\n",
    "            res.append(resInner)\n",
    "        return res\n",
    "                \n",
    "class DefaultScanOffsetsSettingsGenerator():\n",
    "    \n",
    "    _paths = ['ExpControl/scan/range/x/off',\n",
    "              'ExpControl/scan/range/y/off',\n",
    "              'ExpControl/scan/range/z/off'\n",
    "             ]\n",
    "    \n",
    "    def __init__(self, locationGenerator, asMeasurements=True, fun=None):\n",
    "        self.locationGenerator = locationGenerator\n",
    "        self.asMeasurements = asMeasurements\n",
    "        if fun is None:\n",
    "            self.fun = locationGenerator.get_locations\n",
    "        else:\n",
    "            self.fun = fun\n",
    "    \n",
    "    def __call__(self):\n",
    "        locs = self.fun()\n",
    "        \n",
    "        res = []\n",
    "        for loc in locs:\n",
    "            resD = {}\n",
    "            path = cycle(self._paths)\n",
    "            for l in loc:\n",
    "                resD = update_dicts(resD, gen_json(l, next(path)))\n",
    "            res.append([(resD, {})])\n",
    "        if self.asMeasurements:\n",
    "            return res\n",
    "        else:\n",
    "            return [reduce(add, res)]\n",
    "        \n",
    "        \n",
    "\n",
    "class DefaultStageOffsetsSettingsGenerator(DefaultScanOffsetsSettingsGenerator):\n",
    "    _paths = ['ExpControl/scan/range/offsets/coarse/x/g_off',\n",
    "             'ExpControl/scan/range/offsets/coarse/y/g_off',\n",
    "             'ExpControl/scan/range/offsets/coarse/z/g_off']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class DefaultLocationRemover():\n",
    "    \"\"\"\n",
    "    this wrapper can be used to remove location-related updates from the output\n",
    "    of a settings generator.\n",
    "    if will remove the corresponding settings from every measurement dict\n",
    "    and leave the rest as-is.\n",
    "    \"\"\"\n",
    "    \n",
    "    _filtersToRemove = ['ExpControl/scan/range/offsets',\n",
    "                       'ExpControl/scan/range/x/off',\n",
    "                       'ExpControl/scan/range/x/g_off',\n",
    "                       'ExpControl/scan/range/y/off',\n",
    "                       'ExpControl/scan/range/y/g_off',\n",
    "                       'ExpControl/scan/range/z/off',\n",
    "                       'ExpControl/scan/range/z/g_off',\n",
    "                       'OlympusIX/stage',\n",
    "                       'OlympusIX/scanrange']\n",
    "    \n",
    "    def __init__(self, coordinateProvider):\n",
    "        self.coordinateProvider = coordinateProvider\n",
    "    \n",
    "    def __call__(self):\n",
    "        res = []\n",
    "        for l in self.coordinateProvider():\n",
    "            lModified = []\n",
    "            for meas, settings in l:\n",
    "                measI = deepcopy(meas)\n",
    "                for f in DefaultLocationRemover._filtersToRemove:\n",
    "                    measI = remove_filter_from_dict(measI, f)\n",
    "                    if measI is None:\n",
    "                        measI = {}\n",
    "                lModified.append((measI, settings))\n",
    "                \n",
    "            res.append(lModified)\n",
    "        return res\n",
    "    \n",
    "def get_current_stage_coords(im = None):\n",
    "    \n",
    "    if im is None:\n",
    "        im = Imspector()\n",
    "        \n",
    "    im.create_measurement()\n",
    "    ms = im.active_measurement()\n",
    "    \n",
    "    coords = [ms.parameters('ExpControl/scan/range/offsets/coarse/'+ c + '/g_off') for c in 'xyz']\n",
    "    \n",
    "    im.close(ms)\n",
    "    \n",
    "    return coords\n",
    "\n",
    "def dump_JSON(d, path):\n",
    "    \"\"\"\n",
    "    helper function to dump a dict to a file given by path as JSON\n",
    "    \"\"\"\n",
    "    with open(path, 'w') as fd:\n",
    "        json.dump(d, fd, indent=2)\n",
    "        \n",
    "class SpiralOffsetGenerator():\n",
    "    def __init__(self):\n",
    "        self.fov = [5e-5, 5e-5]\n",
    "        self.start = [0, 0]\n",
    "        self.gen = _relative_spiral_generator(self.fov, self.start)\n",
    "    def withFOV(self, fov):\n",
    "        self.fov = fov\n",
    "        self.gen = _relative_spiral_generator(self.fov, self.start)\n",
    "        return self\n",
    "    def withStart(self, start):\n",
    "        self.start = start\n",
    "        self.gen = _relative_spiral_generator(self.fov, self.start)\n",
    "        return self\n",
    "    def get_locations(self):\n",
    "        return [next(self.gen)]\n",
    "    \n",
    "import collections\n",
    "from copy import deepcopy\n",
    "\n",
    "def update_dicts(*dicts):\n",
    "    if len(dicts) == 0:\n",
    "        return {}\n",
    "    \n",
    "    first = dicts[0]\n",
    "    if len(dicts) < 2:\n",
    "        return deepcopy(first)\n",
    "    else:\n",
    "        second = dicts[1]\n",
    "        return update_dicts(update_dict_pair(first, second), *dicts[2:])\n",
    "\n",
    "def update_dict_pair(d1, d2):\n",
    "    res = deepcopy(d1)\n",
    "    for k, v in d2.items():\n",
    "        if (isinstance(v, collections.Mapping)):\n",
    "            res[k] = update_dict_pair(res.get(k) if isinstance(res.get(k, None), collections.Mapping) else {}, v)\n",
    "        else:\n",
    "            res[k] = v\n",
    "    return res\n",
    "\n",
    "def remove_filter_from_dict(d, flt, sep='/'):\n",
    "    \n",
    "    flt_strp = flt.strip(sep)\n",
    "    flts = flt_strp.split(sep)    \n",
    "    fst_flt = flts[0]\n",
    "    \n",
    "    if fst_flt == '':\n",
    "        return None\n",
    "    \n",
    "    if len(flts) == 1:\n",
    "        if (isinstance(d, collections.Sequence) and fst_flt.isdigit()):\n",
    "            try:\n",
    "                cpy = deepcopy(d)\n",
    "                cpy.pop(int(fst_flt))\n",
    "                return cpy if len(cpy) > 0 else None\n",
    "            except IndexError:\n",
    "                return deepcopy(d)\n",
    "        elif (isinstance(d, collections.Mapping)):\n",
    "            try:\n",
    "                cpy = deepcopy(d)\n",
    "                del cpy[fst_flt]\n",
    "                return cpy if len(cpy) > 0 else None                \n",
    "            except KeyError:\n",
    "                return deepcopy(d)\n",
    "        else:\n",
    "            return deepcopy(d)\n",
    "    \n",
    "    if (isinstance(d, collections.Sequence) and fst_flt.isdigit()):\n",
    "        try:\n",
    "            res = remove_filter_from_dict(d[int(fst_flt)], sep.join(flts[1:]))\n",
    "            cpy = deepcopy(d)\n",
    "            if res is None:\n",
    "                del cpy[int(fst_flt)]\n",
    "            else:\n",
    "                cpy[int(fst_flt)] = res\n",
    "            return cpy if len(cpy) > 0 else None\n",
    "        except IndexError:\n",
    "            return deepcopy(d)\n",
    "        \n",
    "    elif (isinstance(d, collections.Mapping)):\n",
    "        try:\n",
    "            res = remove_filter_from_dict(d[fst_flt], sep.join(flts[1:]))\n",
    "            cpy = deepcopy(d)\n",
    "            if res is None:\n",
    "                del cpy[fst_flt]\n",
    "            else:\n",
    "                cpy[fst_flt] = res\n",
    "            return cpy if len(cpy) > 0 else None\n",
    "        except KeyError:\n",
    "            return deepcopy(d)\n",
    "    else:\n",
    "        return None    \n",
    "    \n",
    "    \n",
    "        \n",
    "def filter_dict(d, flt, keepStructure=True, sep='/'):\n",
    "    \n",
    "    flt_strp = flt.strip(sep)\n",
    "    flts = flt_strp.split(sep)\n",
    "    \n",
    "    fst_flt = flts[0]\n",
    "    \n",
    "    if fst_flt == '':\n",
    "        return d\n",
    "    \n",
    "    if len(flts) == 1:\n",
    "        if (isinstance(d, collections.Sequence) and fst_flt.isdigit()):\n",
    "            try:\n",
    "                return [d[int(fst_flt)]] if keepStructure else d[int(fst_flt)]\n",
    "            except IndexError:\n",
    "                return None\n",
    "        elif (isinstance(d, collections.Mapping)):\n",
    "            try:\n",
    "                return {fst_flt: d[fst_flt]} if keepStructure else d[fst_flt]\n",
    "            except KeyError:\n",
    "                return None\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    if (isinstance(d, collections.Sequence) and fst_flt.isdigit()):\n",
    "        try:\n",
    "            res = filter_dict(d[int(fst_flt)], sep.join(flts[1:]), keepStructure)\n",
    "            if res is None:\n",
    "                return None\n",
    "            return [res] if keepStructure else res\n",
    "        except IndexError:\n",
    "            return None\n",
    "    elif (isinstance(d, collections.Mapping)):\n",
    "        try:\n",
    "            res = filter_dict(d[fst_flt], sep.join(flts[1:]), keepStructure)\n",
    "            if res is None:\n",
    "                return None\n",
    "            return {fst_flt: res} if keepStructure else res\n",
    "        except KeyError:\n",
    "            return None\n",
    "    else:\n",
    "        return None    \n",
    "    \n",
    "def gen_json(data, path, sep='/'):\n",
    "    \n",
    "    path_strp = path.strip(sep)\n",
    "    paths = path_strp.split(sep)    \n",
    "    fst_path = paths[0]\n",
    "    \n",
    "    if fst_path == '':\n",
    "        return data\n",
    "    else:\n",
    "        return {fst_path: gen_json(data, sep.join(paths[1:]))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "DefaultLocationRemover(JSONFileConfigLoader(['C:/Users/RESOLFT/Desktop/atest.json', 'C:/Users/RESOLFT/Desktop/atest.json']))()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "m = MagicMock()\n",
    "AcquisitionTaskGenerator(\"a\", lambda: [[(1,2)], [(2,3)]], lambda: [[(5,6)]])(m)\n",
    "c = m.method_calls[0]\n",
    "\n",
    "print(c[1][0].getUpdates(0))\n",
    "print(c[1][0].numAcquisitions)\n",
    "\n",
    "len(m.method_calls)\n",
    "\n",
    "from operator import add\n",
    "from functools import reduce\n",
    "\n",
    "\n",
    "    \n",
    "#pprint(DefaultLocationRemover(lambda: [[(ms.parameters(''), {})]])())\n",
    "\n",
    "\n",
    "g = _relative_spiral_generator([2,2])\n",
    "a = DefaultStageOffsetsSettingsGenerator(None, fun=lambda: [next(g)])\n",
    "\n",
    "atg = AcquisitionTaskGenerator(1, a)\n",
    "m = MagicMock()\n",
    "\n",
    "atg(m)\n",
    "atg(m)\n",
    "\n",
    "DefaultScanOffsetsSettingsGenerator(LegacySpotPairFinder(NewestDataSelector(m, \"overview\"), 3, [.01, .01]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from specpy import *\n",
    "im = Imspector()\n",
    "ms = im.active_measurement()\n",
    "dump_JSON(ms.parameters(''), 'C:/Users/RESOLFT/Desktop/config_json/goldbeads_overview.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pll = PipelineLevels('overview', 'detail')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "atg = (AcquisitionTaskGenerator(pll.overview, \n",
    "                               DefaultLocationRemover(JSONFileConfigLoader(['C:/Users/RESOLFT/Desktop/config_json/goldbeads_overview.json'])),\n",
    "                               DefaultStageOffsetsSettingsGenerator(SpiralOffsetGenerator().withStart(get_current_stage_coords(im))))\n",
    "       .withDelay(.5))\n",
    "\n",
    "\n",
    "\n",
    "pl = (AcquisitionPipeline('1')\n",
    "        .withImspectorConnection(ImspectorConnection(im))\n",
    "        .withPipelineLevels(pll)\n",
    "        .withNameHandler(DefaultNameHandler('C:/Users//RESOLFT/Desktop/TEST_GEN/', pll))\n",
    "        .withAddedStoppingCondition(TimedStoppingCriterion(25))\n",
    "        .withCallbackAtLevel(atg, pll.overview))\n",
    "\n",
    "atg2 = AcquisitionTaskGenerator(pll.detail,\n",
    "                               NewestSettingsSelector(pl, pll.overview))\n",
    "\n",
    "pl.withCallbackAtLevel(atg2, pll.overview)\n",
    "\n",
    "atg(pl)\n",
    "\n",
    "pl.run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "               \n",
    "            \n",
    "            \n",
    "pll = PipelineLevels('overview', 'detail', 'sted')\n",
    "tsk = AcquisitionTask(pll.overview).withDelay(.0)\n",
    "\n",
    "pl = (AcquisitionPipeline('1')\n",
    "        .withImspectorConnection(ImspectorConnection(im))\n",
    "        .withPipelineLevels(pll)\n",
    "        .withNameHandler(DefaultNameHandler('C:/Users//RESOLFT/Desktop/TEST_GEN/', pll))\n",
    "        .withAddedStoppingCondition(TimedStoppingCriterion(15))\n",
    "        .withInitialTask(tsk, pll.overview)\n",
    "        .withCallbackAtLevel(AcquisitionTask(pll.overview).withDelay(.3), pll.overview)\n",
    "        .withCallbackAtLevel(lambda x: print(LegacySpotPairFinder(2, [.003, .003], [1,1]).get_locations(NewestDataSelector(pl, pll.overview).get_data())), pll.overview))\n",
    "pl.run()\n",
    "\n",
    "\n",
    "'''\n",
    "pl = (AcquisitionPipeline('2')\n",
    "        .withPipelineLevels(pll)\n",
    "        .withNameHandler(DefaultNameHandler('aaa', pll))\n",
    "        .withAddedStoppingCondition(TimedStoppingCriterion(5))\n",
    "        .withInitialTask(tsk, pll.overview))\n",
    "pl.run()\n",
    "'''  \n",
    "\n",
    "\n",
    "#print(pl.data[(0,)].measurementSettings[0])\n",
    "print(pl.data[(0,)].numImages(0))\n",
    "pl.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "ds = NewestDataSelector(pl, pll.overview)\n",
    "ds.get_data().data[0]\n",
    "\n",
    "plt.imshow(np.apply_along_axis(np.mean, 0, ds.get_data().data[0][0][0,:,:,:]), cmap='inferno')\n",
    "\n",
    "LegacySpotPairFinder(2, [.001, .001], [1,1]).get_locations(ds.get_data())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "g = _relative_spiral_generator([2,2])\n",
    "[next(g) for _ in range(12)]\n",
    "tuple([1])\n",
    "callable(lambda: np.arange(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imspector stuff from here on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import specpy as sp\n",
    "im = sp.Imspector()\n",
    "im.version()\n",
    "\n",
    "im.active_measurement().parameters('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ms = im.create_measurement()\n",
    "im.activate(ms)\n",
    "\n",
    "#im.run(ms)\n",
    "ms.clone(ms.active_configuration())\n",
    "#im.run(ms)\n",
    "import json\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "d1 = {'a' : {'B' : 2, 'b' : [1,2,3]}}\n",
    "d2 = {'a' : {'B' : 2}}\n",
    "d3 = {'a' : 3}\n",
    "\n",
    "d = update_dicts(d1, d2)\n",
    "print(d)\n",
    "\n",
    "update_dicts(filter_dict(d1, 'a/'), d2)\n",
    "\n",
    "print(remove_filter_from_dict(d1, '/a/B'))\n",
    "filter_dict(d1, 'a/b', False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ms = im.active_measurement()\n",
    "#pprint(ms.parameters(''))\n",
    "upd = update_dicts(filter_dict(dict(ms.parameters('')), '', keepStructure=False))\n",
    "\n",
    "pprint(upd)\n",
    "\n",
    "gen = _relative_spiral_generator([1e-5, 1e-5])\n",
    "\n",
    "for _ in range(10):\n",
    "    xy = next(gen)\n",
    "    upd = update_dicts(gen_json(xy[0], 'ExpControl/scan/range/offsets/coarse/x/g_off'),\n",
    "                       gen_json(xy[1], 'ExpControl/scan/range/offsets/coarse/y/g_off'))\n",
    "\n",
    "    pprint(upd)\n",
    "\n",
    "    ms.set_parameters('', upd)\n",
    "    sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#im.active_measurement().clone(im.active_measurement().active_configuration())\n",
    "im.run(im.active_measurement())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "it = count()\n",
    "\n",
    "\n",
    "ms = im.create_measurement()\n",
    "ms.set_parameters('', params)\n",
    "\n",
    "im.connect_begin(lambda : next(it), 1)\n",
    "im.run(ms)\n",
    "\n",
    "params = ms.parameters('')\n",
    "js = json.dumps(ms.parameters(''), indent=2)\n",
    "\n",
    "im.close(ms)\n",
    "print(next(it))\n",
    "\n",
    "print(js)\n",
    "justoix = dict([(k,v) for k,v in params.items() if (k == 'OlympusIX')])\n",
    "\n",
    "#pprint(im.parameters(''))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
