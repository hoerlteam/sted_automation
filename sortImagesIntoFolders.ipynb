{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import shutil\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import gaussian_filter, imread, median_filter, gaussian_laplace, sobel\n",
    "from skimage.feature import peak_local_max\n",
    "from scipy.spatial import kdtree\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.externals import joblib\n",
    "import pickle\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = [6, 6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def mkdir_if_necessary(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def exists_with_postfix(path, postfix=\".jpg\"):\n",
    "    return os.path.exists(path + postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sort_overviews(d):\n",
    "    files = next(os.walk(d))[2]\n",
    "\n",
    "    ov_d = os.path.join(d, 'overviews')\n",
    "    mkdir_if_necessary(ov_d)\n",
    "\n",
    "    p = re.compile('.*?field.*?sted.*?')\n",
    "\n",
    "    for f in files:\n",
    "        if not re.match(p, f):\n",
    "            shutil.move(os.path.join(d, f), os.path.join(ov_d, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def recommend_quality(im, thresh_brightest = 10, max_dist=25):\n",
    "    i1 = im[:,:,0]\n",
    "    g1 = gaussian_filter(i1, 1)\n",
    "    i2 = im[:,:,1]\n",
    "    g2 = gaussian_filter(i2, 1)\n",
    "    p1 = peak_local_max(g1, min_distance=2)\n",
    "    p2 = peak_local_max(g2, min_distance=2)\n",
    "    \n",
    "    p1i = sorted([(i1[p1[i,0], p1[i,1]], i) for i in range(len(p1))], key=lambda x: x[0], reverse=True)\n",
    "    p2i = sorted([(i2[p2[i,0], p2[i,1]], i) for i in range(len(p2))], key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    if p1i[0][0] < thresh_brightest / 2 * np.mean(i1):\n",
    "        print('BAD: channel 1 dark')\n",
    "        return 'b'\n",
    "    \n",
    "    if p2i[0][0] < thresh_brightest / 2 * np.mean(i2):\n",
    "        print('BAD: channel 2 dark')\n",
    "        return 'b'\n",
    "    \n",
    "    if p1i[0][0] < thresh_brightest * np.mean(i1):\n",
    "        print('MEDIOCRE: channel 1 dark')\n",
    "        return 'm'\n",
    "    \n",
    "    if p2i[0][0] < thresh_brightest * np.mean(i2):\n",
    "        print('MEDIOCRE: channel 2 dark')\n",
    "        return 'm'\n",
    "        \n",
    "    \n",
    "    halflife1 = sum([p1i[i][0] > 0.67 * p1i[0][0] for i in range(len(p1i))]) \n",
    "    halflife2 = sum([p2i[i][0] > 0.67 * p2i[0][0] for i in range(len(p2i))]) \n",
    "    \n",
    "    print('Found ' + str(halflife1) + ' candidate peaks in channel 1')\n",
    "    print('Found ' + str(halflife2) + ' candidate peaks in channel 2')\n",
    "    \n",
    "    if (halflife1 > 5):\n",
    "        print('BAD: found too many peaks in channel 1')\n",
    "        return 'b'\n",
    "    \n",
    "    if (halflife2 > 5):\n",
    "        print('BAD: found too many peaks in channel 2')\n",
    "        return 'b'\n",
    "    \n",
    "    p1good = [p1[p1i[i][1]] for i in range(halflife1)]\n",
    "    p2good = [p2[p2i[i][1]] for i in range(halflife2)]\n",
    "    tree = kdtree.KDTree(p1good)\n",
    "    \n",
    "    mindist = np.min(tree.query(p2good)[0])\n",
    "    print('approximate minimal distance: ' + str(mindist))\n",
    "    \n",
    "    if (mindist > max_dist):\n",
    "        print('MEDIOCRE: minimal distance too high')\n",
    "        return 'm'\n",
    "    \n",
    "    print('GOOD')\n",
    "    return 'g'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def getfeatures(img):\n",
    "    \n",
    "    i1 = im[:,:,0]\n",
    "    g1 = gaussian_filter(i1, 1)\n",
    "    i2 = im[:,:,1]\n",
    "    g2 = gaussian_filter(i2, 1)\n",
    "    p1 = peak_local_max(g1, min_distance=2)\n",
    "    p2 = peak_local_max(g2, min_distance=2)\n",
    "    \n",
    "    p1i = sorted([(i1[p1[i,0], p1[i,1]], i) for i in range(len(p1))], key=lambda x: x[0], reverse=True)\n",
    "    p2i = sorted([(i2[p2[i,0], p2[i,1]], i) for i in range(len(p2))], key=lambda x: x[0], reverse=True)\n",
    "    \n",
    "    halflife1 = sum([p1i[i][0] > 0.67 * p1i[0][0] for i in range(len(p1i))]) \n",
    "    halflife2 = sum([p2i[i][0] > 0.67 * p2i[0][0] for i in range(len(p2i))])\n",
    "    \n",
    "    #print(halflife1)\n",
    "    #print(halflife2)\n",
    "    \n",
    "    p1good = [p1[p1i[i][1]] for i in range(halflife1)]\n",
    "    p2good = [p2[p2i[i][1]] for i in range(halflife2)]\n",
    "    tree = kdtree.KDTree(p1good)\n",
    "    \n",
    "    q = tree.query(p2good)\n",
    "    \n",
    "    m2 = np.argmin(q[0])\n",
    "    m1 = q[1][m2]\n",
    "    d = q[0][m2]\n",
    "    \n",
    "    features = [halflife1, halflife2, d]\n",
    "    \n",
    "    for sigma in [0.7, 1 , 1.5 , 2.25 , 3.5, 5]:\n",
    "        features.append(gaussian_filter(i1,sigma)[tuple(p1good[m1])])\n",
    "        features.append(gaussian_filter(i2,sigma)[tuple(p2good[m2])])\n",
    "        features.append(gaussian_laplace(i1,sigma)[tuple(p1good[m1])])\n",
    "        features.append(gaussian_laplace(i2,sigma)[tuple(p2good[m2])])\n",
    "    \n",
    "    features.append(sobel(i1)[tuple(p1good[m1])])\n",
    "    features.append(sobel(i2)[tuple(p2good[m2])])\n",
    "    features.append(i1[tuple(p1good[m1])])\n",
    "    features.append(i2[tuple(p2good[m2])])\n",
    "    \n",
    "    return [float(f) for f in features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict_ml(img, sc, cls):\n",
    "    feat = np.array(getfeatures(img)).reshape(1,-1)\n",
    "    return ['good', 'bad', 'mediocre'][cls.predict(sc.transform(feat))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# init features\n",
    "features = []\n",
    "classes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# calculate features and classes from\n",
    "# list of dictionaries to use as training data\n",
    "ds = ['/Users/david/Desktop/9th_shipment_20170216/mixed_HS2_HBG2_A/K562/']\n",
    "\n",
    "for d in ds:\n",
    "    for di, _ , fl in os.walk(d):\n",
    "        for f in fl:\n",
    "            if f.endswith('.jpg') and di.split(os.sep)[-1] in ['good', 'bad', 'mediocre']:\n",
    "                im = imread(os.path.join(di, f))\n",
    "                features.append(getfeatures(im))\n",
    "                classes.append(['good', 'bad', 'mediocre'].index(di.split(os.sep)[-1]))\n",
    "\n",
    "#print(features)\n",
    "#print(classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# generate scaler and Random Forrest classifier\n",
    "\n",
    "#print(classes)\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(features)\n",
    "\n",
    "cls = RandomForestClassifier(n_estimators=100)\n",
    "cls.fit(sc.transform(features), [0 if x == 0 else 1 for x in classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save classifier and scaler\n",
    "\n",
    "with open('/Users/david/Desktop/scaler2.pks', 'wb') as fd:\n",
    "    pickle.dump(sc, fd)\n",
    "#with open('/Users/david/Desktop/scaler.pks', 'rb') as fd:\n",
    "#    sc2 = pickle.load(fd)\n",
    "    \n",
    "with open('/Users/david/Desktop/goodbadclassifier2.pks', 'wb') as fd:\n",
    "    pickle.dump(cls, fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#with open('/Users/david/Desktop/scaler2.pks', 'rb') as fd:\n",
    "#    sc = pickle.load(fd)\n",
    "#with open('/Users/david/Desktop/scaler.pks', 'rb') as fd:\n",
    "#    sc2 = pickle.load(fd)\n",
    "    \n",
    "with open('/Users/david/Desktop/goodbadclassifier2.pks', 'rb') as fd:\n",
    "    cls = pickle.load(fd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 1: set the directory to process\n",
    "#dir_to_process = os.path.join(os.getcwd(), 'AutomatedAcquisitions')\n",
    "dir_to_process = '/Users/david/Desktop/6th_shipment_20161219/mixed_HS1345_HS2_B/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### 2: move all the overview files into a separate folder\n",
    "dirs = [d for d in next(os.walk(dir_to_process))[1] if not d.startswith('.')]\n",
    "print(dirs)\n",
    "\n",
    "for d in dirs:\n",
    "    sort_overviews(os.path.join(dir_to_process, d))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### 3: set subfolder to process\n",
    "d = os.path.join(dir_to_process, 'K562_180sec_B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### 4: SORTING into good/bad/mediocre\n",
    "\n",
    "\n",
    "gd_d = os.path.join(d, 'good')\n",
    "bd_d = os.path.join(d, 'bad')\n",
    "md_d = os.path.join(d, 'mediocre')\n",
    "\n",
    "mkdir_if_necessary(gd_d)\n",
    "mkdir_if_necessary(bd_d)\n",
    "mkdir_if_necessary(md_d)\n",
    "\n",
    "files = [f for f in next(os.walk(d))[2] if f.endswith('.msr')]\n",
    "\n",
    "for fi in files:\n",
    "    f = os.path.join(d,fi)\n",
    "    im = imread(f + \".jpg\")\n",
    "    \n",
    "    #rec = predict_ml(im, sc, cls)\n",
    "    plt.imshow(im)\n",
    "    #print(rec.upper())\n",
    "    plt.show()\n",
    "    print('-----')\n",
    "    sys.stdout.flush()\n",
    "    decision = input(\"ISGOOD? [(g)ood/(b)ad/(m)ediocre] :\") #or rec\n",
    "    dec = decision.upper()[0]\n",
    "    \n",
    "    # print(dec == \"G\")\n",
    "    \n",
    "    if dec == \"G\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(gd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(gd_d, fi + \".jpg\"))\n",
    "    elif dec == \"B\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(bd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(bd_d, fi + \".jpg\"))\n",
    "    elif dec == \"M\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(md_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(md_d, fi + \".jpg\"))\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "### 4a: SORTING into good/bad/(mediocre) AUTOMATED\n",
    "\n",
    "\n",
    "gd_d = os.path.join(d, 'good')\n",
    "bd_d = os.path.join(d, 'bad')\n",
    "md_d = os.path.join(d, 'mediocre')\n",
    "\n",
    "mkdir_if_necessary(gd_d)\n",
    "mkdir_if_necessary(bd_d)\n",
    "mkdir_if_necessary(md_d)\n",
    "\n",
    "files = [f for f in next(os.walk(d))[2] if f.endswith('.msr')]\n",
    "\n",
    "for fi in files:\n",
    "    f = os.path.join(d,fi)\n",
    "    im = imread(f + \".jpg\")\n",
    "    \n",
    "    rec = predict_ml(im, sc, cls)\n",
    "    dec = rec.upper()[0]\n",
    "    \n",
    "    if dec == \"G\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(gd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(gd_d, fi + \".jpg\"))\n",
    "    elif dec == \"B\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(bd_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(bd_d, fi + \".jpg\"))\n",
    "    elif dec == \"M\":\n",
    "        shutil.move(os.path.join(d, fi), os.path.join(md_d, fi))\n",
    "        shutil.move(os.path.join(d, fi + \".jpg\"), os.path.join(md_d, fi + \".jpg\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
