{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# autoSTED Basics\n",
    "\n",
    "This notebook showcases how our callback-based autoSTED framework functions in principle.\n",
    "\n",
    "We will first show what acquisition tasks are, how they can be added to the acquisition queue from callbacks and how a pipeline can be built from small, reusable, building blocks. For more realistic applications, please also check out the other notebooks in the examples folder.\n",
    "\n",
    "**Note:** Imspector should be open in the background.\n",
    "\n",
    "The main class to run an acquisition is ```AcquisitionPipeline```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted import AcquisitionPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an ```AcquisitionPipeline``` instance, we have to give it a path to which data should be saved and a list of the *hierarchy levels* of the images to acquire.\n",
    "\n",
    "Here, we make a pipeline with only one hierarchy level ```image``` for demonstration purposes, but in realistic scenarios this could be something like ```['overview', 'detail']```, indicating that we first take overview images in which we then take detail images.\n",
    "\n",
    "The acquisition can then be started with the ```.run()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will do nothing (except creating the output directory if it does not yet exist).\n",
    "\n",
    "That is because we have not added any *acquisition tasks* to the pipeline's queue.\n",
    "\n",
    "## Acquisition Tasks\n",
    "\n",
    "Acquisition tasks are made from parameter dictionaries used in Imspector.\n",
    "\n",
    "For example, let's get the measurement parameters of the current measurement as well as the hardware parameters from Imspector via specpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import specpy as sp\n",
    "\n",
    "# connect to Imspector\n",
    "imspector = sp.get_application()\n",
    "\n",
    "# get current measurement parameters as dict\n",
    "measurement_parameters = imspector.value_at('', sp.ValueTree.Measurement).get()\n",
    "# get hardware parameters / calibrations as dict\n",
    "hardware_parameters = imspector.value_at('', sp.ValueTree.Hardware).get()\n",
    "\n",
    "measurement_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *acquisition task* usable in our pipeline is a list of pairs of measurement and hardware parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make acquisition task: list of (measurement parameters, hardware parameters) pairs\n",
    "acquisition_task = [ (measurement_parameters, hardware_parameters) ]\n",
    "\n",
    "# NOTE: you can use empty hardware parameters ({}), if you do not want to change them\n",
    "# unless you know what you are doing this may be the safer option\n",
    "acquisition_task = [ (measurement_parameters, {}) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the task (at hierarchy level image) to the queue of our pipeline using ```.enqueue_task()```.\n",
    "\n",
    "If we run the pipeline afterwards, the measurements in the queue will be done:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "\n",
    "# enqueue our task \n",
    "pipeline.enqueue_task('image', acquisition_task)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should make a new measurement in Imspector, run an acquistion with the parameters we have specified, save it and then stop because we only added one task to the queue.\n",
    "\n",
    "The resulting image data should be saved in the output path with filename: ```{random string}_image_0.msr```. Instead of the random prefix you can manually specify a prefix for your files via the ```file_prefix``` parameter of AcquisitionPipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, of course, add multiple tasks to the queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "\n",
    "# enqueue task twice \n",
    "pipeline.enqueue_task('image', acquisition_task)\n",
    "pipeline.enqueue_task('image', acquisition_task)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will run the same measurement twice, resulting in two output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** The reason why we have a list of parameter pairs is that this way, we can support multiple configurations.\n",
    "\n",
    "The following code will run the same acquisition twice as two configurations of one measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement with two configurations \n",
    "double_acquisition_task = [ (measurement_parameters, {}), (measurement_parameters, {}) ]\n",
    "\n",
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "\n",
    "pipeline.enqueue_task('image', double_acquisition_task)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the resulting data will be save to one file, similar to manually making multiple configurations in Imspector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Generation Callbacks\n",
    "\n",
    "Instead of manually putting a list of measurements to be done in our pipeline's queue before running them all, we typically generate tasks via callbacks. This way, new tasks can be added while the pipeline is running.\n",
    "\n",
    "In principle, a task generation callback can be any function that returns a hierarchy level and a list of acquisition tasks (in the format specified above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_generation_callback():\n",
    "    return 'image', [ acquisition_task ]\n",
    "\n",
    "task_generation_callback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A callback can be run once at the beginning of the acquisition by passing it to the ```.run()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "pipeline.run(initial_callback=task_generation_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More realistically, we might want to call the callback repeatedly after each image.\n",
    "\n",
    "This can be done via the ```.add_callback()``` method of the pipeline.\n",
    "\n",
    "**Note:** Since this keeps re-adding the acquisition task to the queue, it will run indefinitely until you manually stop via the stop button in Jupyter or via clicking ```Ctrl-C```. In this case, the currently running image will be finished and the pipeline will stop afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "\n",
    "# add task_generation_callback to be run after each acquisition of level 'image'\n",
    "pipeline.add_callback(task_generation_callback, level='image')\n",
    "\n",
    "pipeline.run(initial_callback=task_generation_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To not run forever, we can add *stopping conditions* to our pipeline. For example, a ```MaximumAcquisitionsStoppingCriterion``` will cause the pipeline to stop after a certain number of images have been acquired.\n",
    "\n",
    "In the ```autosted.stoppingcriteria``` module, we also have stopping criteria to e.g. stop after a specific time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.stoppingcriteria import MaximumAcquisitionsStoppingCriterion\n",
    "\n",
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "\n",
    "pipeline.add_callback(task_generation_callback, 'image')\n",
    "\n",
    "# add stopping criterion to stop after 5 images\n",
    "pipeline.add_stopping_condition(MaximumAcquisitionsStoppingCriterion(5))\n",
    "\n",
    "pipeline.run(initial_callback=task_generation_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Useful callbacks via building blocks\n",
    "\n",
    "Until now, we have only run the same acquisition over and over. To actually do something useful, we want our callbacks to enqueue acquisitions with different parameters each time they are run.\n",
    "\n",
    "For this, we offer a variety of *building block callbacks* in ```autosted``` that return a subset of parameters. E.g. a ```SpiralOffsetGenerator``` will generate new stage positions each time it is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.callback_buildingblocks.regular_position_generators import SpiralOffsetGenerator\n",
    "from autosted.imspector import get_current_stage_coords\n",
    "\n",
    "# generator of stage positions in a spiral, with 50x50 micron steps, starting at current position\n",
    "stage_position_generator = SpiralOffsetGenerator(move_size=[50e-6, 50e-6], start_position=get_current_stage_coords())\n",
    "\n",
    "# call 4 times and print result\n",
    "for _ in range(4):\n",
    "    print(stage_position_generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple callbacks can be combined using an ```AcquisitionTaskGenerator``` object.\n",
    "\n",
    "This combined callback will thus first load full measurement parameters from a dictionary (or file if we instead give it a file path) using a ```JSONSettingsLoader``` and then overwrite just the stage position parameters with changing values supplied by the ```SpiralOffsetGenerator```. Finally, the merged parameters will be returned as acquisition tasks at level 'image'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.taskgeneration import AcquisitionTaskGenerator\n",
    "from autosted.callback_buildingblocks.static_settings import JSONSettingsLoader\n",
    "\n",
    "next_overview_generator = AcquisitionTaskGenerator('image',\n",
    "                         JSONSettingsLoader(measurement_parameters),\n",
    "                         SpiralOffsetGenerator(move_size=[50e-6, 50e-6], start_position=get_current_stage_coords()))\n",
    "\n",
    "pipeline = AcquisitionPipeline(data_save_path='acquisition_data/test', hierarchy_levels=['image'])\n",
    "\n",
    "pipeline.add_callback(next_overview_generator, 'image')\n",
    "\n",
    "pipeline.add_stopping_condition(MaximumAcquisitionsStoppingCriterion(5))\n",
    "\n",
    "pipeline.run(initial_callback=next_overview_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
