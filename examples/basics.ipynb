{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **autoSTED** Basics\n",
    "\n",
    "This notebook showcases how our **autoSTED** framework and its core components of an acquisition task queue with callbacks functions in principle.\n",
    "\n",
    "We will first show what acquisition tasks are, how they can be added to the acquisition task queue by callbacks and how a pipeline can be built from small, reusable, building blocks. For more realistic applications, please also check out the other notebooks in the examples folder.\n",
    "\n",
    "**Note:** Imspector should be open in the background.\n",
    "\n",
    "The main class to run an acquisition is ```AcquisitionPipeline```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted import AcquisitionPipeline\n",
    "\n",
    "# activate logging, as autoSTED uses it for some output\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create an ```AcquisitionPipeline``` instance, we have to give it a path to which data should be saved and a list of the *hierarchy levels* of the images to acquire.\n",
    "\n",
    "Here, we make a pipeline with only one hierarchy level ```'image'``` for demonstration purposes, but in realistic scenarios this could be something like ```['overview', 'detail']```, indicating that we first take overview images in which we then take detail images.\n",
    "\n",
    "The acquisition can then be started with the ```.run()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will do nothing (except creating the output directory if it does not yet exist).\n",
    "\n",
    "That is because we have not added any *acquisition tasks* to the pipeline's queue.\n",
    "\n",
    "## Acquisition Tasks\n",
    "\n",
    "Acquisition tasks are made from **parameter dictionaries** that correspond to the value trees used in Imspector.\n",
    "\n",
    "For example, let's get the measurement parameters of the current measurement as well as the hardware parameters from Imspector via SpecPy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import specpy as sp\n",
    "\n",
    "# connect to Imspector\n",
    "imspector = sp.get_application()\n",
    "\n",
    "# get current measurement parameters as dict\n",
    "measurement_parameters = imspector.value_at(\"\", sp.ValueTree.Measurement).get()\n",
    "# get hardware parameters / calibrations as dict\n",
    "hardware_parameters = imspector.value_at(\"\", sp.ValueTree.Hardware).get()\n",
    "\n",
    "measurement_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An *acquisition task* usable in our pipeline is a list of pairs of measurement and hardware parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make acquisition task: list of (measurement parameters, hardware parameters) pairs\n",
    "acquisition_task = [(measurement_parameters, hardware_parameters)]\n",
    "\n",
    "# NOTE: you can use empty hardware parameters ({}), if you do not want to change them\n",
    "# unless you know what you are doing this may be the safer option\n",
    "acquisition_task = [(measurement_parameters, {})]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can add the task (at hierarchy level image) to the queue of our pipeline using ```.enqueue_task()```.\n",
    "\n",
    "If we run the pipeline afterwards, the measurements in the queue will be run one after the other:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "\n",
    "# enqueue our task\n",
    "pipeline.enqueue_task(\"image\", acquisition_task)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will make a new measurement in Imspector, run an acquistion with the parameters we have specified, save it and then stop because we only added one task to the queue.\n",
    "\n",
    "The resulting image data will be saved in the output path with filename: ```{random string}_image_0.msr```.\n",
    "\n",
    "Instead of the random prefix you can manually specify a prefix for your files via the ```file_prefix``` parameter of AcquisitionPipeline. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can, of course, add multiple tasks to the queue:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "\n",
    "# enqueue task twice\n",
    "pipeline.enqueue_task(\"image\", acquisition_task)\n",
    "pipeline.enqueue_task(\"image\", acquisition_task)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will run the same measurement twice, resulting in two output files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Configurations\n",
    "\n",
    "The reason why our Acquisition Tasks are a list of parameter pairs (instead of a single one) is that this way, we can support multiple configurations.\n",
    "\n",
    "The following code will run the same acquisition twice, but as two configurations of one measurement:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurement with two configurations\n",
    "double_acquisition_task = [\n",
    "    (measurement_parameters, {}),\n",
    "    (measurement_parameters, {}),\n",
    "]\n",
    "\n",
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "\n",
    "pipeline.enqueue_task(\"image\", double_acquisition_task)\n",
    "\n",
    "pipeline.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the resulting data will be saved to one file, similar to manually making multiple configurations in Imspector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task Generation Callbacks\n",
    "\n",
    "Instead of manually putting a list of measurements to be done in our pipeline's queue before running them all, we typically generate tasks via **callbacks**. This way, new tasks can be added while the pipeline is running.\n",
    "\n",
    "In principle, a task generation callback can be any function (or callable object) that returns a hierarchy level and a list of acquisition tasks (in the format specified above):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_generation_callback():\n",
    "    return \"image\", [acquisition_task]\n",
    "\n",
    "\n",
    "task_generation_callback()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A callback can be run once at the beginning of the acquisition by passing it to the ```.run()``` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "pipeline.run(initial_callback=task_generation_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More realistically, we might want to call the callback repeatedly after each image.\n",
    "\n",
    "This can be done via the ```.add_callback()``` method of the pipeline, which will cause the callback to be run every time a measurement of a given level is finished.\n",
    "\n",
    "**Note:** Since this keeps re-adding the acquisition task to the queue, it will run indefinitely until you manually stop via the stop button in Jupyter or via clicking ```Ctrl-C```. In this case, the currently running image will be finished and the pipeline will stop afterwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "\n",
    "# add task_generation_callback to be run after each acquisition of level 'image'\n",
    "pipeline.add_callback(task_generation_callback, level=\"image\")\n",
    "\n",
    "pipeline.run(initial_callback=task_generation_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To not run forever, we can add *stopping conditions* to our pipeline. For example, a ```MaximumAcquisitionsStoppingCriterion``` will cause the pipeline to stop after a certain number of images have been acquired.\n",
    "\n",
    "In the ```autosted.stoppingcriteria``` module, we also have stopping criteria to e.g. stop after a specific time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.stoppingcriteria import MaximumAcquisitionsStoppingCriterion\n",
    "\n",
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "\n",
    "pipeline.add_callback(task_generation_callback, \"image\")\n",
    "\n",
    "# add stopping criterion to stop after 5 images\n",
    "pipeline.add_stopping_condition(MaximumAcquisitionsStoppingCriterion(5))\n",
    "\n",
    "pipeline.run(initial_callback=task_generation_callback)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assembling callbacks from building blocks\n",
    "\n",
    "Until now, we have only run the same acquisition over and over. To actually do something useful, we want our callbacks to enqueue acquisitions with different parameters each time they are run.\n",
    "\n",
    "For this, we offer a variety of *building block callbacks* in ```autosted``` that return a subset of parameters. E.g. a ```SpiralOffsetGenerator``` will generate new stage positions each time it is called:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.callback_buildingblocks import SpiralOffsetGenerator\n",
    "from autosted.imspector import get_current_stage_coords\n",
    "\n",
    "# generator of stage positions in a spiral, with 50x50 micron steps, starting at current position\n",
    "stage_position_generator = SpiralOffsetGenerator(\n",
    "    move_size=[50e-6, 50e-6], start_position=get_current_stage_coords()\n",
    ")\n",
    "\n",
    "# call 4 times and print result\n",
    "for _ in range(4):\n",
    "    print(stage_position_generator())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple callbacks can be combined using an ```AcquisitionTaskGenerator``` object.\n",
    "\n",
    "In the followng block, we use this to construct a combined callback that will first load full measurement parameters from a dictionary (or file if we instead give it a file path) using a ```JSONSettingsLoader``` and then overwrite just the stage position parameters with changing values supplied by the ```SpiralOffsetGenerator```. Finally, the merged parameters will be returned as acquisition tasks at level 'image'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.taskgeneration import AcquisitionTaskGenerator\n",
    "from autosted.callback_buildingblocks import JSONSettingsLoader\n",
    "\n",
    "next_overview_generator = AcquisitionTaskGenerator(\n",
    "    \"image\",\n",
    "    # building block 1: return base measurement parameters\n",
    "    JSONSettingsLoader(measurement_parameters),\n",
    "    # building block 2: return stage coordinates\n",
    "    # (moving in spiral every time it is called)\n",
    "    SpiralOffsetGenerator(\n",
    "        move_size=[50e-6, 50e-6], start_position=get_current_stage_coords()\n",
    "    ),\n",
    ")\n",
    "\n",
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test\", hierarchy_levels=[\"image\"]\n",
    ")\n",
    "\n",
    "pipeline.add_callback(next_overview_generator, \"image\")\n",
    "\n",
    "pipeline.add_stopping_condition(MaximumAcquisitionsStoppingCriterion(5))\n",
    "\n",
    "pipeline.run(initial_callback=next_overview_generator)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-py312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
