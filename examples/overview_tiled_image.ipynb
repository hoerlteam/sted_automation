{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import specpy\n",
    "\n",
    "from autosted.callback_buildingblocks.coordinate_value_wrappers import StageOffsetsSettingsGenerator\n",
    "from autosted.callback_buildingblocks.regular_position_generators import PositionListOffsetGenerator\n",
    "from autosted.callback_buildingblocks.parameter_filtering import LocationRemover\n",
    "from autosted.callback_buildingblocks.static_settings import FOVSettingsGenerator\n",
    "from autosted.detection import SimpleFocusPlaneDetector\n",
    "from autosted.callback_buildingblocks.value_wrappers import SimpleManualOffset\n",
    "from autosted.callback_buildingblocks.data_selection import NewestDataSelector\n",
    "from autosted.utils.tiling import centered_tiles\n",
    "from autosted.callback_buildingblocks.static_settings import JSONSettingsLoader\n",
    "from autosted.taskgeneration import AcquisitionTaskGenerator\n",
    "from autosted.pipeline import AcquisitionPipeline\n",
    "from autosted.imspector import get_current_stage_coords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where to save & whether to save combined HDF5 file\n",
    "save_folder = 'examples/acquisition_data/large_image_test'\n",
    "save_hdf5 = True\n",
    "\n",
    "# path of measurement parameters (dumped to JSON file)\n",
    "# measurement_parameters = 'C:/Users/RESOLFT/Desktop/config_json/gabi/20240307_590_480_overview.json'\n",
    "# alternative: use current from Imspector\n",
    "measurement_parameters = specpy.get_application().value_at('', specpy.ValueTree.Measurement).get()\n",
    "\n",
    "# yx FOV size\n",
    "fov_size = [50e-6, 50e-6]\n",
    "\n",
    "# yx number of tiles\n",
    "n_tiles = [4, 4]\n",
    "\n",
    "# how much the tiles should overlap (0-1)\n",
    "overlap_fraction = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current coordinates and print, so we can go back to that position\n",
    "start_coords = get_current_stage_coords()\n",
    "print(start_coords)\n",
    "\n",
    "# generate regular grid around current stage position\n",
    "# NOTE: we add empty z-fov size and 1 tile to get 3d coordinates\n",
    "coordinate_list = centered_tiles(start_coords, fov_size=[0]+fov_size, n_tiles=[1]+n_tiles, overlap=overlap_fraction)\n",
    "coordinate_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline object (just one level: 'field')\n",
    "pipeline = AcquisitionPipeline(save_folder, ['field'], save_combined_hdf5=save_hdf5, name='multipoint-acquisition')\n",
    "\n",
    "# callback that will create an acquisition task with given measurement parameters\n",
    "# at the next stage coordinates in the coordinate list (the next 'position')\n",
    "next_position_generator = AcquisitionTaskGenerator('field',\n",
    "    LocationRemover(JSONSettingsLoader(measurement_parameters)),\n",
    "    PositionListOffsetGenerator(coordinate_list),\n",
    "    FOVSettingsGenerator(lengths=[None] + fov_size),\n",
    "    )\n",
    "\n",
    "# attach callback so that after each position, the next one will be enqueued\n",
    "pipeline.add_callback(next_position_generator, 'field')\n",
    "\n",
    "# start with initial task from callback\n",
    "pipeline.run(next_position_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel to focus in\n",
    "focus_channel = 0\n",
    "\n",
    "# manual offset (zyx) to focus\n",
    "manual_focus_offset = [0, 0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build pipeline object (just one level: 'field')\n",
    "pipeline = AcquisitionPipeline(save_folder, ['field'], save_combined_hdf5=save_hdf5, name='multipoint-acquisition')\n",
    "\n",
    "# callback that will create an acquisition task with given measurement parameters\n",
    "# at the next stage coordinates in the coordinate list (the next 'position')\n",
    "next_position_generator = AcquisitionTaskGenerator('field',\n",
    "    LocationRemover(JSONSettingsLoader(measurement_parameters)),\n",
    "    PositionListOffsetGenerator(coordinate_list),\n",
    "    FOVSettingsGenerator(lengths=[None] + fov_size),\n",
    "    StageOffsetsSettingsGenerator(\n",
    "        SimpleManualOffset(\n",
    "            SimpleFocusPlaneDetector(\n",
    "                NewestDataSelector(pipeline, level='field'),\n",
    "                channel=focus_channel\n",
    "        ), offset=manual_focus_offset))\n",
    "    )\n",
    "\n",
    "# attach callback so that after each position, the next one will be enqueued\n",
    "pipeline.add_callback(next_position_generator, 'field')\n",
    "\n",
    "# start with initial task from callback\n",
    "pipeline.run(next_position_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.utils.parameter_constants import DIRECTION_STAGE, PIXEL_SIZE_PARAMETERS\n",
    "from autosted.utils.dict_utils import get_parameter_value_array_from_dict\n",
    "from calmutils.stitching import stitch\n",
    "from calmutils.stitching.fusion import fuse_image\n",
    "from calmutils.stitching.transform_helpers import translation_matrix\n",
    "\n",
    "# index of flipped axes\n",
    "flip_axes = [i for i,d in enumerate(DIRECTION_STAGE) if d < 0]\n",
    "\n",
    "# generate dummy regular grid around current stage position with flipped coordinates\n",
    "coordinate_list_for_stitch = centered_tiles(\n",
    "    start_coords,\n",
    "    fov_size=[0]+fov_size,\n",
    "    n_tiles=[1]+n_tiles,\n",
    "    overlap=overlap_fraction,\n",
    "    flip_axes=flip_axes)\n",
    "\n",
    "# get images of a particular channel and configuration\n",
    "configuration = 0\n",
    "channel = 0\n",
    "images = [v.data[configuration][channel].squeeze() for v in pipeline.data.values()]\n",
    "\n",
    "is2d = images[0].ndim == 2\n",
    "\n",
    "# get pixel size\n",
    "settings = pipeline.data[(0,)].measurement_settings[configuration]\n",
    "pixel_sizes = get_parameter_value_array_from_dict(settings, PIXEL_SIZE_PARAMETERS)\n",
    "\n",
    "# build (pixel-unit) transform matrix from coordinates\n",
    "transforms = [translation_matrix((c/pixel_sizes)[(1 if is2d else 0):]) for c in coordinate_list_for_stitch]\n",
    "\n",
    "# fuse into one image\n",
    "fused = fuse_image(images, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative: with registration\n",
    "transforms = stitch(images, [(c/pixel_sizes)[(1 if is2d else 0):] for c in coordinate_list_for_stitch], corr_thresh=0.9)\n",
    "\n",
    "# fuse into one image\n",
    "fused = fuse_image(images, transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.imshow(fused, cmap='magma')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autosted-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
