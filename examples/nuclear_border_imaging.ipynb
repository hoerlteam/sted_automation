{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d824f458",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu, gaussian\n",
    "from skimage.morphology import disk, dilation, erosion, label, remove_small_holes, remove_small_objects\n",
    "from skimage.segmentation import clear_border\n",
    "from skimage.measure import regionprops\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def segment(\n",
    "        img,\n",
    "        blur_sigma = 3,\n",
    "        expansion_radius = 3,\n",
    "        minimal_average_signal = 0,\n",
    "        only_largest = False,\n",
    "        return_outlines = False,\n",
    "    ):\n",
    "\n",
    "    g = gaussian(img, blur_sigma)\n",
    "\n",
    "    mask = g > threshold_otsu(g)\n",
    "    mask = remove_small_holes(mask, 200)\n",
    "    mask = remove_small_objects(mask, 200)\n",
    "    mask = clear_border(mask)\n",
    "\n",
    "    labels = label(mask)\n",
    "    labels = dilation(labels, disk(expansion_radius))\n",
    "\n",
    "    outlines = (labels > 0) ^ erosion(mask, disk(expansion_radius))\n",
    "\n",
    "    # discard objects with average signal below minimum\n",
    "    for rp in regionprops(labels, img):\n",
    "        if rp.intensity_mean < minimal_average_signal:\n",
    "            labels[rp.slice][rp.image] = 0\n",
    "            outlines[rp.slice][rp.image] = 0\n",
    "\n",
    "    # keep largest\n",
    "    if only_largest:\n",
    "        rps = sorted(regionprops(labels), key = attrgetter('area'), reverse=True)\n",
    "        for rp in rps[1:]:\n",
    "            labels[rp.slice][rp.image] = 0\n",
    "            outlines[rp.slice][rp.image] = 0\n",
    "\n",
    "    return (labels, outlines) if return_outlines else labels\n",
    "\n",
    "\n",
    "def get_tiled_outlines(\n",
    "        img,\n",
    "        tile_size = 10,\n",
    "        **segment_kwargs\n",
    "    ):\n",
    "\n",
    "    _, outlines = segment(img, return_outlines=True, **segment_kwargs)\n",
    "\n",
    "    n_tiles_shape = tuple(int(s/tile_size) + 1 for s in outlines.shape)\n",
    "    n_tiles = np.prod(n_tiles_shape)\n",
    "\n",
    "    tiles_full = np.arange(1, n_tiles+1).reshape(n_tiles_shape)\n",
    "    for d, n in enumerate(n_tiles_shape):\n",
    "        tiles_full = np.repeat(tiles_full, tile_size, d)\n",
    "\n",
    "    # cut to img shape\n",
    "    tiles_full = tiles_full[*(slice(0,s) for s in outlines.shape)]\n",
    "\n",
    "    return tiles_full * outlines\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276424ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import specpy as sp\n",
    "\n",
    "imspector = sp.get_application()\n",
    "ms = imspector.active_measurement()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff0d73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = ms.stack('STAR ORANGE_CONF {0}').data()\n",
    "\n",
    "# max projection or just squeeze for 2d\n",
    "# projection = img.max(axis=(0,1))\n",
    "projection = img.squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dff55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from functools import partial\n",
    "\n",
    "# make single-parameter function that we can use in pipeline\n",
    "# (alternatively, we could also pass a kwarg dict when constructing callbacks below)\n",
    "segment_fun = partial(segment, expansion_radius=6, minimal_average_signal=5)\n",
    "tiled_outlines_fun = partial(get_tiled_outlines, expansion_radius=4)\n",
    "\n",
    "labels = segment_fun(projection)\n",
    "tiled_outlines = tiled_outlines_fun(projection)\n",
    "\n",
    "fig, axs = plt.subplots(ncols=3, figsize=(12,4))\n",
    "axs[0].imshow(projection)\n",
    "axs[1].imshow(labels)\n",
    "axs[2].imshow(tiled_outlines, cmap='turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8beb26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted import AcquisitionPipeline\n",
    "from autosted.taskgeneration import AcquisitionTaskGenerator\n",
    "from autosted.callback_buildingblocks import (\n",
    "    JSONSettingsLoader,\n",
    "    LocationRemover,\n",
    "    SpiralOffsetGenerator,\n",
    "    LocationKeeper,\n",
    "    NewestSettingsSelector\n",
    ")\n",
    "from autosted.imspector import get_current_stage_coords, ImspectorConnection\n",
    "from autosted.stoppingcriteria import (\n",
    "    MaximumAcquisitionsStoppingCriterion,\n",
    ")\n",
    "from autosted.detection import SegmentationWrapper\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "# path to parameters\n",
    "confocal_config = \"config_json/20251119_2d_640_ov.json\"\n",
    "sted_config = \"config_json/20251119_2d_640_detail.json\"\n",
    "\n",
    "# 3-level pipeline overview, cell (confocal), border_tile (STED)\n",
    "# NOTE: the intermediate cell level is not strictly necessary, but helps group the tiles\n",
    "pipeline = AcquisitionPipeline(\n",
    "    data_save_path=\"acquisition_data/test_border_5_untiled\",\n",
    "    hierarchy_levels=[\"overview\", 'cell', 'border_tile'],\n",
    "    save_combined_hdf5=True\n",
    ")\n",
    "\n",
    "# for shorter delays between measurements, we can re-use them (still WIP)\n",
    "pipeline.imspector_connection = ImspectorConnection(reuse_measurement=True)\n",
    "\n",
    "# callback 1: next overviews in spiral\n",
    "next_overview_generator = AcquisitionTaskGenerator(\n",
    "    \"overview\",\n",
    "    LocationRemover(JSONSettingsLoader(confocal_config)),\n",
    "    SpiralOffsetGenerator(\n",
    "        move_size=[75e-6, 75e-6],\n",
    "        start_position=get_current_stage_coords(),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# callback 2: confocal image of individual cells\n",
    "cell_generator = AcquisitionTaskGenerator(\n",
    "    \"cell\",\n",
    "    LocationRemover(JSONSettingsLoader(confocal_config)),\n",
    "    LocationKeeper(NewestSettingsSelector()),\n",
    "    # TODO?: return segmentation results as stage offsets -> move cell to center?\n",
    "    # did introduce some inacurate movement though\n",
    "    SegmentationWrapper(segment_fun, offset_parameters='scan'),\n",
    ")\n",
    "\n",
    "# callback 3: STED images on tiled border of cell\n",
    "sted_generator = AcquisitionTaskGenerator(\n",
    "    \"border_tile\",\n",
    "    LocationRemover(JSONSettingsLoader(sted_config)),\n",
    "    LocationKeeper(NewestSettingsSelector()),\n",
    "    # SegmentationWrapper(tiled_outlines_fun),\n",
    "    SegmentationWrapper(segment_fun)\n",
    ")\n",
    "\n",
    "# add the callbacks and a stopping condition\n",
    "pipeline.add_callback(next_overview_generator, \"overview\")\n",
    "pipeline.add_callback(cell_generator, \"overview\")\n",
    "pipeline.add_callback(sted_generator, \"cell\")\n",
    "pipeline.add_stopping_condition(\n",
    "    MaximumAcquisitionsStoppingCriterion(max_acquisitions_per_level={\"overview\": 10})\n",
    ")\n",
    "\n",
    "pipeline.run(initial_callback=next_overview_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b52a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py as h5\n",
    "import time\n",
    "import datetime\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "from natsort import natsort_keygen\n",
    "\n",
    "df = defaultdict(list)\n",
    "\n",
    "with h5.File('acquisition_data/test_border_4/ea0a0374.h5') as fd:\n",
    "    \n",
    "    for k in fd['experiment'].keys():\n",
    "\n",
    "        dataset_config0 = fd[f'experiment/{k}/0']\n",
    "        start_time = dataset_config0.attrs['run_start_time']\n",
    "        end_time = dataset_config0.attrs['run_end_time']\n",
    "        start_time = datetime.datetime.fromtimestamp(start_time)\n",
    "        end_time = datetime.datetime.fromtimestamp(end_time)\n",
    "\n",
    "        df['meas_idx'].append(k)\n",
    "        df['start_time'].append(start_time)\n",
    "        df['end_time'].append(end_time)\n",
    "\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "# naturally sort by measurement idx -> chronological order\n",
    "df = df.sort_values(by='meas_idx', key=natsort_keygen()).reset_index(drop=True)\n",
    "\n",
    "df['dt_from_previous'] = df.start_time - df.shift(1).end_time\n",
    "df['meas_duration'] = df.end_time - df.start_time\n",
    "\n",
    "df.dt_from_previous.mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autosted-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
