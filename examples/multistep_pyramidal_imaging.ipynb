{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import specpy\n",
    "from itertools import pairwise, product\n",
    "\n",
    "def divide_into_tiles(img, num_divisions=2, threshold=0, min_size_fraction=0.05):\n",
    "\n",
    "    # num_divisions can be sequence (per dimension)\n",
    "    # if only a scalar is given, we re-use it for all dimensions \n",
    "    if np.isscalar(num_divisions):\n",
    "        num_divisions = [num_divisions] * img.ndim\n",
    "\n",
    "    # get all candidate bboxes\n",
    "    bboxes = []\n",
    "    start_end_per_dimension = [map(list, pairwise(np.linspace(0, s, n+1))) for s,n in zip(img.shape, num_divisions)]\n",
    "    for bbox in map(list, product(*start_end_per_dimension)):\n",
    "        bboxes.append(np.array(bbox).T)\n",
    "\n",
    "    # select only the ones with enough intensity in img\n",
    "    bboxes_above_thresh = []\n",
    "    for bbox in bboxes:\n",
    "        # select tile defined by bbox rounded to nearest pixel\n",
    "        start, end = bbox\n",
    "        start = np.round(start).astype(int)\n",
    "        end = np.round(end).astype(int)\n",
    "        tile = img[tuple(slice(s,e) for s,e in zip(start, end))]\n",
    "        # if fraction of pixels above threshold is above minimal size fraction,\n",
    "        # accept into final list of bboxes\n",
    "        if (tile >= threshold).sum() / tile.size >= min_size_fraction:\n",
    "            bboxes_above_thresh.append(bbox.ravel())\n",
    "\n",
    "    return bboxes_above_thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = specpy.get_application()\n",
    "img = im.active_measurement().stack(0).data().squeeze()\n",
    "\n",
    "divide_into_tiles(img, threshold=4, num_divisions=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted import AcquisitionPipeline\n",
    "from autosted.taskgeneration import AcquisitionTaskGenerator\n",
    "from autosted.callback_buildingblocks.static_settings import JSONSettingsLoader, FOVSettingsGenerator\n",
    "from autosted.detection.roi_detection import ROIDetectorWrapper\n",
    "from autosted.utils.dict_utils import get_parameter_value_array_from_dict\n",
    "from autosted.utils.parameter_constants import PIXEL_SIZE_PARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get current measurement from Imspector\n",
    "im = specpy.get_application()\n",
    "params = im.value_at(\"\", specpy.ValueTree.Measurement).get()\n",
    "\n",
    "# get pixel size of active measurement\n",
    "pixel_size = get_parameter_value_array_from_dict(params, PIXEL_SIZE_PARAMETERS)\n",
    "\n",
    "pipeline = AcquisitionPipeline(\"acquisition_data/pyramid\", [\"level0\", \"level1\"])\n",
    "\n",
    "# initial image at double pixel size (i.e. half resolution)\n",
    "start_callback = AcquisitionTaskGenerator(\n",
    "    \"level0\",\n",
    "    JSONSettingsLoader(params),\n",
    "    FOVSettingsGenerator(pixel_sizes=pixel_size*2)\n",
    ")\n",
    "\n",
    "# get ROIs to image at level1 with original pixel size using divide_into_tiles\n",
    "tile_callback = AcquisitionTaskGenerator(\n",
    "    \"level1\",\n",
    "    JSONSettingsLoader(params),\n",
    "    ROIDetectorWrapper(divide_into_tiles, detection_kwargs={\"threshold\": 4})\n",
    ")\n",
    "\n",
    "pipeline.add_callback(tile_callback, \"level0\")\n",
    "pipeline.run(start_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im = specpy.get_application()\n",
    "params = im.value_at(\"\", specpy.ValueTree.Measurement).get()\n",
    "\n",
    "pixel_size = get_parameter_value_array_from_dict(params, PIXEL_SIZE_PARAMETERS)\n",
    "\n",
    "pipeline = AcquisitionPipeline(\"acquisition_data/pyramid\", [\"level0\", \"level1\", \"level2\"])\n",
    "\n",
    "# by default, increasing levels have a lower priority number, i.e. they will be imaged first\n",
    "# by giving them increasing priorities, we can instead do a breadth-first traversal\n",
    "pipeline.level_priorities = {\"level0\": 0, \"level1\": 1, \"level2\": 2}\n",
    "\n",
    "# first overview at 9-fold subsampling\n",
    "start_callback = AcquisitionTaskGenerator(\n",
    "    \"level0\",\n",
    "    JSONSettingsLoader(params),\n",
    "    FOVSettingsGenerator(pixel_sizes=pixel_size*9)\n",
    ")\n",
    "\n",
    "# second level at 3-fold subsampling\n",
    "tile_callback_l1 = AcquisitionTaskGenerator(\n",
    "    \"level1\",\n",
    "    JSONSettingsLoader(params),\n",
    "    FOVSettingsGenerator(pixel_sizes=pixel_size*3),\n",
    "    ROIDetectorWrapper(divide_into_tiles, detection_kwargs={\"threshold\": 5, \"num_divisions\": 3})\n",
    ")\n",
    "\n",
    "# 3rd level at original pixel size\n",
    "tile_callback_l2 = AcquisitionTaskGenerator(\n",
    "    \"level2\",\n",
    "    JSONSettingsLoader(params),\n",
    "    ROIDetectorWrapper(divide_into_tiles, detection_kwargs={\"threshold\": 5, \"num_divisions\": 3})\n",
    ")\n",
    "\n",
    "pipeline.add_callback(tile_callback_l1, \"level0\")\n",
    "pipeline.add_callback(tile_callback_l2, \"level1\")\n",
    "pipeline.run(start_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.callback_buildingblocks.parameter_filtering import LocationRemover\n",
    "\n",
    "pipeline = AcquisitionPipeline(\"acquisition_data/pyramid\", [\"level0\", \"level1\"])\n",
    "\n",
    "start_callback = AcquisitionTaskGenerator(\n",
    "    \"level0\",\n",
    "    LocationRemover(JSONSettingsLoader(\"config_json/test_overview.json\")),\n",
    ")\n",
    "\n",
    "tile_callback = AcquisitionTaskGenerator(\n",
    "    \"level1\",\n",
    "    LocationRemover(JSONSettingsLoader(\"config_json/test_detail.json\")),\n",
    "    ROIDetectorWrapper(divide_into_tiles, detection_kwargs={\"threshold\": 4, \"num_divisions\": 12})\n",
    ")\n",
    "\n",
    "pipeline.add_callback(tile_callback, \"level0\")\n",
    "pipeline.run(start_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autosted.utils.coordinate_utils import approximate_pixel_shift_from_settings\n",
    "from calmutils.stitching.transform_helpers import translation_matrix\n",
    "from calmutils.stitching.fusion import fuse_image\n",
    "\n",
    "level = \"level1\"\n",
    "channel = 1\n",
    "configuration = 0\n",
    "\n",
    "# get all measurement settings and images at selected level, config and channel\n",
    "idx_len = pipeline.hierarchy_levels.index(level) + 1\n",
    "settings = [measurement.measurement_settings[configuration] for idx, measurement in pipeline.data.items() if len(idx) == idx_len]\n",
    "images = [measurement.data[configuration][channel].squeeze() for idx, measurement in pipeline.data.items() if len(idx) == idx_len]\n",
    "\n",
    "# get pixel shifts of all images relative to first\n",
    "pixel_shifts = [approximate_pixel_shift_from_settings(settings[0], setting_i) for setting_i in settings]\n",
    "\n",
    "# to transformation matrix\n",
    "is2d = images[0].ndim == 2\n",
    "transforms = [translation_matrix(shift[(1 if is2d else 0):]) for shift in pixel_shifts]\n",
    "\n",
    "# fuse (low out-of-bounds value to better visualize non-imaged areas)\n",
    "fused = fuse_image(images, transforms, oob_val=-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "ax.imshow(fused, cmap=\"magma\", clim=(-5, 25))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autosted-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
